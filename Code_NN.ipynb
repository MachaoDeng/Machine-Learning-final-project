{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import linalg as la\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from keras import models,layers\n",
    "from keras.layers import Input, Dense, Layer\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import tensorflow.keras.datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('high_diamond_ranked_10min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>blueWins</th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueWardsDestroyed</th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>...</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalExperience</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redCSPerMin</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4519157822</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16567</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17047</td>\n",
       "      <td>197</td>\n",
       "      <td>55</td>\n",
       "      <td>-643</td>\n",
       "      <td>8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1656.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4523371949</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17620</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17438</td>\n",
       "      <td>240</td>\n",
       "      <td>52</td>\n",
       "      <td>2908</td>\n",
       "      <td>1173</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4521474530</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17285</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17254</td>\n",
       "      <td>203</td>\n",
       "      <td>28</td>\n",
       "      <td>1172</td>\n",
       "      <td>1033</td>\n",
       "      <td>20.3</td>\n",
       "      <td>1728.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4524384067</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17961</td>\n",
       "      <td>235</td>\n",
       "      <td>47</td>\n",
       "      <td>1321</td>\n",
       "      <td>7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1647.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4436033771</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18313</td>\n",
       "      <td>225</td>\n",
       "      <td>67</td>\n",
       "      <td>1004</td>\n",
       "      <td>-230</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1740.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>4527873286</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15246</td>\n",
       "      <td>6.8</td>\n",
       "      <td>16498</td>\n",
       "      <td>229</td>\n",
       "      <td>34</td>\n",
       "      <td>-2519</td>\n",
       "      <td>-2469</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1524.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>4527797466</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15456</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18367</td>\n",
       "      <td>206</td>\n",
       "      <td>56</td>\n",
       "      <td>-782</td>\n",
       "      <td>-888</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1545.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>4527713716</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18319</td>\n",
       "      <td>7.4</td>\n",
       "      <td>19909</td>\n",
       "      <td>261</td>\n",
       "      <td>60</td>\n",
       "      <td>2416</td>\n",
       "      <td>1877</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1831.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>4527628313</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15298</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18314</td>\n",
       "      <td>247</td>\n",
       "      <td>40</td>\n",
       "      <td>839</td>\n",
       "      <td>1085</td>\n",
       "      <td>24.7</td>\n",
       "      <td>1529.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>4523772935</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15339</td>\n",
       "      <td>6.8</td>\n",
       "      <td>17379</td>\n",
       "      <td>201</td>\n",
       "      <td>46</td>\n",
       "      <td>-927</td>\n",
       "      <td>58</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1533.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9879 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gameId  blueWins  blueWardsPlaced  blueWardsDestroyed  \\\n",
       "0     4519157822         0               28                   2   \n",
       "1     4523371949         0               12                   1   \n",
       "2     4521474530         0               15                   0   \n",
       "3     4524384067         0               43                   1   \n",
       "4     4436033771         0               75                   4   \n",
       "...          ...       ...              ...                 ...   \n",
       "9874  4527873286         1               17                   2   \n",
       "9875  4527797466         1               54                   0   \n",
       "9876  4527713716         0               23                   1   \n",
       "9877  4527628313         0               14                   4   \n",
       "9878  4523772935         1               18                   0   \n",
       "\n",
       "      blueFirstBlood  blueKills  blueDeaths  blueAssists  blueEliteMonsters  \\\n",
       "0                  1          9           6           11                  0   \n",
       "1                  0          5           5            5                  0   \n",
       "2                  0          7          11            4                  1   \n",
       "3                  0          4           5            5                  1   \n",
       "4                  0          6           6            6                  0   \n",
       "...              ...        ...         ...          ...                ...   \n",
       "9874               1          7           4            5                  1   \n",
       "9875               0          6           4            8                  1   \n",
       "9876               0          6           7            5                  0   \n",
       "9877               1          2           3            3                  1   \n",
       "9878               1          6           6            5                  0   \n",
       "\n",
       "      blueDragons  ...  redTowersDestroyed  redTotalGold  redAvgLevel  \\\n",
       "0               0  ...                   0         16567          6.8   \n",
       "1               0  ...                   1         17620          6.8   \n",
       "2               1  ...                   0         17285          6.8   \n",
       "3               0  ...                   0         16478          7.0   \n",
       "4               0  ...                   0         17404          7.0   \n",
       "...           ...  ...                 ...           ...          ...   \n",
       "9874            1  ...                   0         15246          6.8   \n",
       "9875            1  ...                   0         15456          7.0   \n",
       "9876            0  ...                   0         18319          7.4   \n",
       "9877            1  ...                   0         15298          7.2   \n",
       "9878            0  ...                   0         15339          6.8   \n",
       "\n",
       "      redTotalExperience  redTotalMinionsKilled  redTotalJungleMinionsKilled  \\\n",
       "0                  17047                    197                           55   \n",
       "1                  17438                    240                           52   \n",
       "2                  17254                    203                           28   \n",
       "3                  17961                    235                           47   \n",
       "4                  18313                    225                           67   \n",
       "...                  ...                    ...                          ...   \n",
       "9874               16498                    229                           34   \n",
       "9875               18367                    206                           56   \n",
       "9876               19909                    261                           60   \n",
       "9877               18314                    247                           40   \n",
       "9878               17379                    201                           46   \n",
       "\n",
       "      redGoldDiff  redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
       "0            -643                  8         19.7         1656.7  \n",
       "1            2908               1173         24.0         1762.0  \n",
       "2            1172               1033         20.3         1728.5  \n",
       "3            1321                  7         23.5         1647.8  \n",
       "4            1004               -230         22.5         1740.4  \n",
       "...           ...                ...          ...            ...  \n",
       "9874        -2519              -2469         22.9         1524.6  \n",
       "9875         -782               -888         20.6         1545.6  \n",
       "9876         2416               1877         26.1         1831.9  \n",
       "9877          839               1085         24.7         1529.8  \n",
       "9878         -927                 58         20.1         1533.9  \n",
       "\n",
       "[9879 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop=['gameId','redFirstBlood','redKills','redDeaths','blueTotalGold','redTotalGold','blueTotalExperience','redTotalExperience']\n",
    "data = rawdata.drop(labels=todrop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.8\n",
    "\n",
    "trainidx = np.random.rand(data.shape[0]) < train_rate\n",
    "\n",
    "train = data[trainidx]\n",
    "test = data[~trainidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train.drop('blueWins',axis=1))\n",
    "train_label = np.array(train['blueWins'])\n",
    "\n",
    "test_data = np.array(test.drop('blueWins',axis=1))\n",
    "test_label = np.array(test['blueWins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normilizer = np.max(train_data,axis=0)\n",
    "\n",
    "train_data=train_data/normilizer\n",
    "test_data=test_data/normilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = to_categorical(train_label)\n",
    "test_label = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maxepoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ReluModel1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,658\n",
      "Trainable params: 14,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ReluModel1 = models.Sequential(name='ReluModel1')\n",
    "\n",
    "ReluModel1.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "ReluModel1.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel1.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel1.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel1.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel1.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "ReluModel1.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReluModel1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 2s 238us/step - loss: 0.5569 - accuracy: 0.7111 - val_loss: 0.5411 - val_accuracy: 0.7285\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 1s 160us/step - loss: 0.5327 - accuracy: 0.7286 - val_loss: 0.5362 - val_accuracy: 0.7218\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5323 - accuracy: 0.7268 - val_loss: 0.5347 - val_accuracy: 0.7280\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5317 - accuracy: 0.7290 - val_loss: 0.5370 - val_accuracy: 0.7264\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5292 - accuracy: 0.7293 - val_loss: 0.5350 - val_accuracy: 0.7269\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5285 - accuracy: 0.7299 - val_loss: 0.5372 - val_accuracy: 0.7275\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5268 - accuracy: 0.7333 - val_loss: 0.5412 - val_accuracy: 0.7239\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 1s 166us/step - loss: 0.5280 - accuracy: 0.7346 - val_loss: 0.5378 - val_accuracy: 0.7218\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 1s 160us/step - loss: 0.5259 - accuracy: 0.7341 - val_loss: 0.5382 - val_accuracy: 0.7295\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5273 - accuracy: 0.7312 - val_loss: 0.5355 - val_accuracy: 0.7208\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5270 - accuracy: 0.7343 - val_loss: 0.5367 - val_accuracy: 0.7280\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 1s 158us/step - loss: 0.5247 - accuracy: 0.7331 - val_loss: 0.5374 - val_accuracy: 0.7228\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 1s 165us/step - loss: 0.5246 - accuracy: 0.7337 - val_loss: 0.5383 - val_accuracy: 0.7295\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 1s 157us/step - loss: 0.5240 - accuracy: 0.7356 - val_loss: 0.5393 - val_accuracy: 0.7264\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5244 - accuracy: 0.7345 - val_loss: 0.5394 - val_accuracy: 0.7182\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5234 - accuracy: 0.7350 - val_loss: 0.5382 - val_accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.5232 - accuracy: 0.7341 - val_loss: 0.5362 - val_accuracy: 0.7198\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5222 - accuracy: 0.7341 - val_loss: 0.5485 - val_accuracy: 0.7208\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5242 - accuracy: 0.7379 - val_loss: 0.5398 - val_accuracy: 0.7269\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5236 - accuracy: 0.7358 - val_loss: 0.5466 - val_accuracy: 0.7259\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 1s 172us/step - loss: 0.5211 - accuracy: 0.7352 - val_loss: 0.5407 - val_accuracy: 0.7290\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5210 - accuracy: 0.7374 - val_loss: 0.5391 - val_accuracy: 0.7218\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5204 - accuracy: 0.7380 - val_loss: 0.5423 - val_accuracy: 0.7239\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 1s 149us/step - loss: 0.5208 - accuracy: 0.7380 - val_loss: 0.5387 - val_accuracy: 0.7300\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 1s 165us/step - loss: 0.5197 - accuracy: 0.7358 - val_loss: 0.5431 - val_accuracy: 0.7275\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 1s 156us/step - loss: 0.5192 - accuracy: 0.7384 - val_loss: 0.5426 - val_accuracy: 0.7249\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 1s 152us/step - loss: 0.5175 - accuracy: 0.7386 - val_loss: 0.5429 - val_accuracy: 0.7285\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 1s 121us/step - loss: 0.5191 - accuracy: 0.7379 - val_loss: 0.5420 - val_accuracy: 0.7167\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 1s 119us/step - loss: 0.5193 - accuracy: 0.7375 - val_loss: 0.5462 - val_accuracy: 0.7264\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.5179 - accuracy: 0.7398 - val_loss: 0.5440 - val_accuracy: 0.7275\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 1s 127us/step - loss: 0.5158 - accuracy: 0.7375 - val_loss: 0.5442 - val_accuracy: 0.7249\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 1s 125us/step - loss: 0.5155 - accuracy: 0.7430 - val_loss: 0.5498 - val_accuracy: 0.7162\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 1s 137us/step - loss: 0.5140 - accuracy: 0.7418 - val_loss: 0.5454 - val_accuracy: 0.7218\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 1s 159us/step - loss: 0.5135 - accuracy: 0.7410 - val_loss: 0.5463 - val_accuracy: 0.7249\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.5123 - accuracy: 0.7406 - val_loss: 0.5453 - val_accuracy: 0.7203\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 1s 168us/step - loss: 0.5121 - accuracy: 0.7390 - val_loss: 0.5531 - val_accuracy: 0.7300\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 1s 162us/step - loss: 0.5096 - accuracy: 0.7456 - val_loss: 0.5464 - val_accuracy: 0.7193\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.5093 - accuracy: 0.7452 - val_loss: 0.5544 - val_accuracy: 0.7188\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 1s 142us/step - loss: 0.5083 - accuracy: 0.7458 - val_loss: 0.5584 - val_accuracy: 0.7275\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.5069 - accuracy: 0.7439 - val_loss: 0.5572 - val_accuracy: 0.7234\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.5061 - accuracy: 0.7439 - val_loss: 0.5792 - val_accuracy: 0.7157\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 1s 139us/step - loss: 0.5058 - accuracy: 0.7448 - val_loss: 0.5548 - val_accuracy: 0.7234\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 1s 138us/step - loss: 0.5034 - accuracy: 0.7474 - val_loss: 0.5567 - val_accuracy: 0.7228\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 1s 143us/step - loss: 0.5028 - accuracy: 0.7483 - val_loss: 0.5617 - val_accuracy: 0.7264\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 1s 159us/step - loss: 0.5010 - accuracy: 0.7500 - val_loss: 0.5707 - val_accuracy: 0.7116\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 1s 145us/step - loss: 0.5001 - accuracy: 0.7515 - val_loss: 0.5585 - val_accuracy: 0.7218\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 1s 147us/step - loss: 0.4973 - accuracy: 0.7503 - val_loss: 0.5767 - val_accuracy: 0.7100\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 1s 141us/step - loss: 0.4955 - accuracy: 0.7554 - val_loss: 0.5632 - val_accuracy: 0.7228\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 1s 158us/step - loss: 0.4966 - accuracy: 0.7524 - val_loss: 0.5656 - val_accuracy: 0.7228\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 1s 130us/step - loss: 0.4924 - accuracy: 0.7561 - val_loss: 0.5786 - val_accuracy: 0.7213\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 1s 140us/step - loss: 0.4911 - accuracy: 0.7549 - val_loss: 0.5784 - val_accuracy: 0.7177\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 1s 122us/step - loss: 0.4903 - accuracy: 0.7570 - val_loss: 0.5856 - val_accuracy: 0.7095\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.4865 - accuracy: 0.7607 - val_loss: 0.5912 - val_accuracy: 0.7182\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 1s 139us/step - loss: 0.4854 - accuracy: 0.7632 - val_loss: 0.5745 - val_accuracy: 0.7234\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 1s 131us/step - loss: 0.4825 - accuracy: 0.7620 - val_loss: 0.5880 - val_accuracy: 0.7111\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 1s 140us/step - loss: 0.4831 - accuracy: 0.7631 - val_loss: 0.5832 - val_accuracy: 0.7106\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 1s 143us/step - loss: 0.4781 - accuracy: 0.7616 - val_loss: 0.5792 - val_accuracy: 0.7147\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 1s 146us/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.6019 - val_accuracy: 0.7152\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 1s 168us/step - loss: 0.4754 - accuracy: 0.7640 - val_loss: 0.6033 - val_accuracy: 0.6993\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 1s 141us/step - loss: 0.4722 - accuracy: 0.7683 - val_loss: 0.5997 - val_accuracy: 0.7177\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 1s 157us/step - loss: 0.4724 - accuracy: 0.7696 - val_loss: 0.6207 - val_accuracy: 0.7039\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 1s 136us/step - loss: 0.4690 - accuracy: 0.7723 - val_loss: 0.6188 - val_accuracy: 0.7095\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 1s 156us/step - loss: 0.4697 - accuracy: 0.7678 - val_loss: 0.6266 - val_accuracy: 0.7131\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 1s 139us/step - loss: 0.4658 - accuracy: 0.7734 - val_loss: 0.6272 - val_accuracy: 0.7218\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 1s 158us/step - loss: 0.4596 - accuracy: 0.7792 - val_loss: 0.6317 - val_accuracy: 0.7013\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 1s 158us/step - loss: 0.4605 - accuracy: 0.7753 - val_loss: 0.6213 - val_accuracy: 0.7121\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 1s 152us/step - loss: 0.4588 - accuracy: 0.7815 - val_loss: 0.6414 - val_accuracy: 0.7193\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 1s 135us/step - loss: 0.4546 - accuracy: 0.7791 - val_loss: 0.6685 - val_accuracy: 0.7106\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.6399 - val_accuracy: 0.7029\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 1s 157us/step - loss: 0.4480 - accuracy: 0.7838 - val_loss: 0.7108 - val_accuracy: 0.7075\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 1s 120us/step - loss: 0.4493 - accuracy: 0.7818 - val_loss: 0.6567 - val_accuracy: 0.6983\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 1s 151us/step - loss: 0.4428 - accuracy: 0.7898 - val_loss: 0.7142 - val_accuracy: 0.7111\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 1s 137us/step - loss: 0.4486 - accuracy: 0.7806 - val_loss: 0.6491 - val_accuracy: 0.7152\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 1s 140us/step - loss: 0.4416 - accuracy: 0.7892 - val_loss: 0.6642 - val_accuracy: 0.7085\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 1s 136us/step - loss: 0.4409 - accuracy: 0.7873 - val_loss: 0.7171 - val_accuracy: 0.6967\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 1s 126us/step - loss: 0.4334 - accuracy: 0.7907 - val_loss: 0.7108 - val_accuracy: 0.7049\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.4322 - accuracy: 0.7934 - val_loss: 0.7289 - val_accuracy: 0.6926\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 1s 121us/step - loss: 0.4308 - accuracy: 0.7930 - val_loss: 0.7230 - val_accuracy: 0.7095\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 1s 149us/step - loss: 0.4252 - accuracy: 0.7939 - val_loss: 0.7881 - val_accuracy: 0.7059\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 1s 124us/step - loss: 0.4267 - accuracy: 0.7949 - val_loss: 0.7341 - val_accuracy: 0.7177\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 1s 128us/step - loss: 0.4224 - accuracy: 0.7998 - val_loss: 0.7375 - val_accuracy: 0.7095\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 1s 123us/step - loss: 0.4230 - accuracy: 0.7936 - val_loss: 0.7668 - val_accuracy: 0.7065\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 1s 136us/step - loss: 0.4143 - accuracy: 0.8006 - val_loss: 0.7639 - val_accuracy: 0.7018\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 1s 139us/step - loss: 0.4163 - accuracy: 0.7998 - val_loss: 0.7758 - val_accuracy: 0.7152\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 1s 151us/step - loss: 0.4081 - accuracy: 0.8042 - val_loss: 0.7736 - val_accuracy: 0.6983\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 1s 157us/step - loss: 0.4121 - accuracy: 0.8050 - val_loss: 0.7713 - val_accuracy: 0.7080\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 1s 144us/step - loss: 0.4087 - accuracy: 0.8032 - val_loss: 0.7502 - val_accuracy: 0.7065\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 1s 133us/step - loss: 0.4016 - accuracy: 0.8086 - val_loss: 0.8565 - val_accuracy: 0.7013\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.4033 - accuracy: 0.8095 - val_loss: 0.7881 - val_accuracy: 0.6957\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 1s 126us/step - loss: 0.3995 - accuracy: 0.8086 - val_loss: 0.8101 - val_accuracy: 0.6849\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 1s 140us/step - loss: 0.3995 - accuracy: 0.8104 - val_loss: 0.7972 - val_accuracy: 0.6839\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 1s 127us/step - loss: 0.3893 - accuracy: 0.8175 - val_loss: 0.8936 - val_accuracy: 0.7008\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 1s 128us/step - loss: 0.3913 - accuracy: 0.8123 - val_loss: 0.8230 - val_accuracy: 0.7121\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 1s 142us/step - loss: 0.3861 - accuracy: 0.8175 - val_loss: 0.8730 - val_accuracy: 0.6855\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 1s 135us/step - loss: 0.3872 - accuracy: 0.8159 - val_loss: 0.9075 - val_accuracy: 0.6983\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 1s 152us/step - loss: 0.3817 - accuracy: 0.8214 - val_loss: 0.9063 - val_accuracy: 0.7013\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 1s 146us/step - loss: 0.3767 - accuracy: 0.8229 - val_loss: 0.9820 - val_accuracy: 0.6926\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 1s 135us/step - loss: 0.3742 - accuracy: 0.8240 - val_loss: 0.9508 - val_accuracy: 0.6983\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 1s 130us/step - loss: 0.3769 - accuracy: 0.8236 - val_loss: 1.0692 - val_accuracy: 0.6870\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 1s 134us/step - loss: 0.3706 - accuracy: 0.8248 - val_loss: 0.9531 - val_accuracy: 0.6916\n"
     ]
    }
   ],
   "source": [
    "history1 = ReluModel1.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ReluModel2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 53,890\n",
      "Trainable params: 53,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ReluModel2 = models.Sequential(name='ReluModel2')\n",
    "\n",
    "ReluModel2.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "ReluModel2.add(layers.Dense(128,activation='relu'))\n",
    "ReluModel2.add(layers.Dense(128,activation='relu'))\n",
    "ReluModel2.add(layers.Dense(128,activation='relu'))\n",
    "ReluModel2.add(layers.Dense(128,activation='relu'))\n",
    "ReluModel2.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "ReluModel2.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReluModel2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 1s 158us/step - loss: 0.5453 - accuracy: 0.7228 - val_loss: 0.5439 - val_accuracy: 0.7213\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 1s 147us/step - loss: 0.5345 - accuracy: 0.7302 - val_loss: 0.5369 - val_accuracy: 0.7300\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 1s 140us/step - loss: 0.5289 - accuracy: 0.7298 - val_loss: 0.5439 - val_accuracy: 0.7244\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 1s 151us/step - loss: 0.5300 - accuracy: 0.7292 - val_loss: 0.5397 - val_accuracy: 0.7213\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 1s 165us/step - loss: 0.5298 - accuracy: 0.7314 - val_loss: 0.5364 - val_accuracy: 0.7280\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 1s 146us/step - loss: 0.5276 - accuracy: 0.7332 - val_loss: 0.5509 - val_accuracy: 0.7259\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 1s 154us/step - loss: 0.5284 - accuracy: 0.7304 - val_loss: 0.5421 - val_accuracy: 0.7290\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 1s 147us/step - loss: 0.5286 - accuracy: 0.7321 - val_loss: 0.5367 - val_accuracy: 0.7239\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 1s 159us/step - loss: 0.5263 - accuracy: 0.7370 - val_loss: 0.5468 - val_accuracy: 0.7203\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 1s 165us/step - loss: 0.5272 - accuracy: 0.7381 - val_loss: 0.5398 - val_accuracy: 0.7244\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5267 - accuracy: 0.7336 - val_loss: 0.5346 - val_accuracy: 0.7208\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5250 - accuracy: 0.7337 - val_loss: 0.5463 - val_accuracy: 0.7182\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5250 - accuracy: 0.7372 - val_loss: 0.5361 - val_accuracy: 0.7275\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 1s 171us/step - loss: 0.5245 - accuracy: 0.7331 - val_loss: 0.5403 - val_accuracy: 0.7295\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 1s 169us/step - loss: 0.5242 - accuracy: 0.7356 - val_loss: 0.5447 - val_accuracy: 0.7152\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 1s 146us/step - loss: 0.5238 - accuracy: 0.7347 - val_loss: 0.5358 - val_accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 1s 148us/step - loss: 0.5228 - accuracy: 0.7352 - val_loss: 0.5405 - val_accuracy: 0.7280\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.5233 - accuracy: 0.7367 - val_loss: 0.5404 - val_accuracy: 0.7234\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5228 - accuracy: 0.7343 - val_loss: 0.5381 - val_accuracy: 0.7280\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5235 - accuracy: 0.7332 - val_loss: 0.5456 - val_accuracy: 0.7259\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5223 - accuracy: 0.7377 - val_loss: 0.5367 - val_accuracy: 0.7264\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5222 - accuracy: 0.7403 - val_loss: 0.5410 - val_accuracy: 0.7290\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5209 - accuracy: 0.7390 - val_loss: 0.5478 - val_accuracy: 0.7310\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.5204 - accuracy: 0.7380 - val_loss: 0.5617 - val_accuracy: 0.7259\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5194 - accuracy: 0.7386 - val_loss: 0.5496 - val_accuracy: 0.7182\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5190 - accuracy: 0.7368 - val_loss: 0.5454 - val_accuracy: 0.7223\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.5182 - accuracy: 0.7352 - val_loss: 0.5441 - val_accuracy: 0.7249\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5162 - accuracy: 0.7389 - val_loss: 0.5568 - val_accuracy: 0.7254\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5162 - accuracy: 0.7396 - val_loss: 0.5447 - val_accuracy: 0.7172\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 1s 174us/step - loss: 0.5182 - accuracy: 0.7372 - val_loss: 0.5515 - val_accuracy: 0.7177\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5167 - accuracy: 0.7380 - val_loss: 0.5493 - val_accuracy: 0.7310\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5153 - accuracy: 0.7371 - val_loss: 0.5424 - val_accuracy: 0.7285\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5132 - accuracy: 0.7391 - val_loss: 0.5533 - val_accuracy: 0.7254\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 1s 174us/step - loss: 0.5114 - accuracy: 0.7400 - val_loss: 0.5469 - val_accuracy: 0.7264\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 1s 172us/step - loss: 0.5133 - accuracy: 0.7408 - val_loss: 0.5514 - val_accuracy: 0.7131\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5098 - accuracy: 0.7404 - val_loss: 0.5452 - val_accuracy: 0.7310\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5100 - accuracy: 0.7425 - val_loss: 0.5565 - val_accuracy: 0.7131\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5068 - accuracy: 0.7462 - val_loss: 0.5557 - val_accuracy: 0.7239\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5066 - accuracy: 0.7462 - val_loss: 0.5472 - val_accuracy: 0.7177\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5059 - accuracy: 0.7462 - val_loss: 0.5568 - val_accuracy: 0.7193\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5036 - accuracy: 0.7437 - val_loss: 0.5756 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5038 - accuracy: 0.7463 - val_loss: 0.5625 - val_accuracy: 0.7264\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5038 - accuracy: 0.7488 - val_loss: 0.5590 - val_accuracy: 0.7193\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.4979 - accuracy: 0.7521 - val_loss: 0.5786 - val_accuracy: 0.7254\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.4975 - accuracy: 0.7515 - val_loss: 0.5743 - val_accuracy: 0.7300\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.4956 - accuracy: 0.7522 - val_loss: 0.5727 - val_accuracy: 0.7182\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.4917 - accuracy: 0.7541 - val_loss: 0.5754 - val_accuracy: 0.7157\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 2s 196us/step - loss: 0.4910 - accuracy: 0.7506 - val_loss: 0.6055 - val_accuracy: 0.7223\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.4915 - accuracy: 0.7549 - val_loss: 0.5826 - val_accuracy: 0.7029\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.4860 - accuracy: 0.7592 - val_loss: 0.6087 - val_accuracy: 0.7249\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.4837 - accuracy: 0.7602 - val_loss: 0.6303 - val_accuracy: 0.7157\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.4809 - accuracy: 0.7632 - val_loss: 0.6209 - val_accuracy: 0.7147\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.4798 - accuracy: 0.7594 - val_loss: 0.5961 - val_accuracy: 0.7234\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.4768 - accuracy: 0.7633 - val_loss: 0.6248 - val_accuracy: 0.7152\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.4719 - accuracy: 0.7652 - val_loss: 0.6252 - val_accuracy: 0.7177\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.4693 - accuracy: 0.7702 - val_loss: 0.6307 - val_accuracy: 0.7218\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.4677 - accuracy: 0.7698 - val_loss: 0.6231 - val_accuracy: 0.7111\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.4628 - accuracy: 0.7734 - val_loss: 0.6321 - val_accuracy: 0.7106\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.4583 - accuracy: 0.7752 - val_loss: 0.6557 - val_accuracy: 0.7177\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 1s 171us/step - loss: 0.4531 - accuracy: 0.7790 - val_loss: 0.6824 - val_accuracy: 0.7152\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.4524 - accuracy: 0.7789 - val_loss: 0.7089 - val_accuracy: 0.7116\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.4455 - accuracy: 0.7825 - val_loss: 0.7333 - val_accuracy: 0.7049\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.4418 - accuracy: 0.7873 - val_loss: 0.7093 - val_accuracy: 0.7116\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.4412 - accuracy: 0.7839 - val_loss: 0.7185 - val_accuracy: 0.7075\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.4385 - accuracy: 0.7873 - val_loss: 0.8242 - val_accuracy: 0.7070\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.4305 - accuracy: 0.7891 - val_loss: 0.7459 - val_accuracy: 0.6926\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 1s 154us/step - loss: 0.4302 - accuracy: 0.7874 - val_loss: 0.7428 - val_accuracy: 0.7044\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.4227 - accuracy: 0.7973 - val_loss: 0.7357 - val_accuracy: 0.7106\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.4171 - accuracy: 0.7958 - val_loss: 0.8120 - val_accuracy: 0.7059\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.4165 - accuracy: 0.7994 - val_loss: 0.8692 - val_accuracy: 0.7100\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.4149 - accuracy: 0.8004 - val_loss: 0.8045 - val_accuracy: 0.6931\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.4117 - accuracy: 0.8023 - val_loss: 0.8603 - val_accuracy: 0.7131\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 1s 156us/step - loss: 0.4031 - accuracy: 0.8110 - val_loss: 0.9357 - val_accuracy: 0.6967\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.3978 - accuracy: 0.8096 - val_loss: 0.9605 - val_accuracy: 0.7126\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.3975 - accuracy: 0.8086 - val_loss: 0.9213 - val_accuracy: 0.7044\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.3896 - accuracy: 0.8148 - val_loss: 0.9794 - val_accuracy: 0.6895\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 2s 202us/step - loss: 0.3875 - accuracy: 0.8183 - val_loss: 0.9463 - val_accuracy: 0.7049\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.3842 - accuracy: 0.8190 - val_loss: 1.0202 - val_accuracy: 0.6890\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.3760 - accuracy: 0.8190 - val_loss: 0.9844 - val_accuracy: 0.6962\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.3752 - accuracy: 0.8220 - val_loss: 1.0155 - val_accuracy: 0.7090\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.3721 - accuracy: 0.8249 - val_loss: 1.1397 - val_accuracy: 0.6998\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.3637 - accuracy: 0.8286 - val_loss: 1.0314 - val_accuracy: 0.7049\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.3624 - accuracy: 0.8267 - val_loss: 1.1728 - val_accuracy: 0.6906\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.3588 - accuracy: 0.8302 - val_loss: 1.0621 - val_accuracy: 0.7013\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.3479 - accuracy: 0.8350 - val_loss: 1.0683 - val_accuracy: 0.6972\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.3487 - accuracy: 0.8388 - val_loss: 1.1777 - val_accuracy: 0.6916\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.3425 - accuracy: 0.8361 - val_loss: 1.1667 - val_accuracy: 0.6895\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.3380 - accuracy: 0.8397 - val_loss: 1.2069 - val_accuracy: 0.6865\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.3298 - accuracy: 0.8469 - val_loss: 1.2459 - val_accuracy: 0.6849\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.3367 - accuracy: 0.8416 - val_loss: 1.2375 - val_accuracy: 0.6952\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.3371 - accuracy: 0.8442 - val_loss: 1.3146 - val_accuracy: 0.6901\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.3310 - accuracy: 0.8477 - val_loss: 1.3075 - val_accuracy: 0.6880\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.3384 - accuracy: 0.8477 - val_loss: 1.1950 - val_accuracy: 0.6998\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.3104 - accuracy: 0.8557 - val_loss: 1.2613 - val_accuracy: 0.6962\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.3081 - accuracy: 0.8568 - val_loss: 1.3967 - val_accuracy: 0.6921\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.3068 - accuracy: 0.8591 - val_loss: 1.3200 - val_accuracy: 0.6814\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.3015 - accuracy: 0.8615 - val_loss: 1.3314 - val_accuracy: 0.6972\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.2946 - accuracy: 0.8612 - val_loss: 1.4457 - val_accuracy: 0.6603\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.2974 - accuracy: 0.8640 - val_loss: 1.5552 - val_accuracy: 0.6972\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.2944 - accuracy: 0.8668 - val_loss: 1.4187 - val_accuracy: 0.6824\n"
     ]
    }
   ],
   "source": [
    "history2 = ReluModel2.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ReluModel3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 19,842\n",
      "Trainable params: 19,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ReluModel3 = models.Sequential(name='ReluModel3')\n",
    "\n",
    "ReluModel3.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "ReluModel3.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(32,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(32,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(32,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(32,activation='relu'))\n",
    "ReluModel3.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "ReluModel3.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReluModel3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 2s 291us/step - loss: 0.5655 - accuracy: 0.6923 - val_loss: 0.5521 - val_accuracy: 0.7249\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5341 - accuracy: 0.7278 - val_loss: 0.5534 - val_accuracy: 0.7198\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 2s 264us/step - loss: 0.5341 - accuracy: 0.7314 - val_loss: 0.5399 - val_accuracy: 0.7259\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5307 - accuracy: 0.7323 - val_loss: 0.5374 - val_accuracy: 0.7223\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5300 - accuracy: 0.7318 - val_loss: 0.5376 - val_accuracy: 0.7244\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5280 - accuracy: 0.7323 - val_loss: 0.5375 - val_accuracy: 0.7244\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.5296 - accuracy: 0.7319 - val_loss: 0.5540 - val_accuracy: 0.7162\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 2s 257us/step - loss: 0.5285 - accuracy: 0.7338 - val_loss: 0.5376 - val_accuracy: 0.7177\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.5265 - accuracy: 0.7375 - val_loss: 0.5403 - val_accuracy: 0.7234\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5258 - accuracy: 0.7336 - val_loss: 0.5373 - val_accuracy: 0.7218\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5251 - accuracy: 0.7348 - val_loss: 0.5443 - val_accuracy: 0.7269\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5255 - accuracy: 0.7347 - val_loss: 0.5385 - val_accuracy: 0.7228\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5270 - accuracy: 0.7355 - val_loss: 0.5418 - val_accuracy: 0.7290\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5264 - accuracy: 0.7337 - val_loss: 0.5374 - val_accuracy: 0.7264\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5243 - accuracy: 0.7348 - val_loss: 0.5392 - val_accuracy: 0.7254\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 2s 283us/step - loss: 0.5240 - accuracy: 0.7368 - val_loss: 0.5473 - val_accuracy: 0.7208\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 2s 283us/step - loss: 0.5252 - accuracy: 0.7352 - val_loss: 0.5386 - val_accuracy: 0.7275\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.5237 - accuracy: 0.7374 - val_loss: 0.5412 - val_accuracy: 0.7249\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 2s 277us/step - loss: 0.5233 - accuracy: 0.7384 - val_loss: 0.5437 - val_accuracy: 0.7203\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 2s 264us/step - loss: 0.5229 - accuracy: 0.7337 - val_loss: 0.5433 - val_accuracy: 0.7198\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 2s 290us/step - loss: 0.5221 - accuracy: 0.7360 - val_loss: 0.5416 - val_accuracy: 0.7280\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 2s 280us/step - loss: 0.5209 - accuracy: 0.7389 - val_loss: 0.5443 - val_accuracy: 0.7234\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 2s 252us/step - loss: 0.5226 - accuracy: 0.7382 - val_loss: 0.5454 - val_accuracy: 0.7167\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 2s 280us/step - loss: 0.5231 - accuracy: 0.7362 - val_loss: 0.5439 - val_accuracy: 0.7269\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.5201 - accuracy: 0.7389 - val_loss: 0.5398 - val_accuracy: 0.7259\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 2s 286us/step - loss: 0.5217 - accuracy: 0.7352 - val_loss: 0.5457 - val_accuracy: 0.7305\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 2s 273us/step - loss: 0.5201 - accuracy: 0.7372 - val_loss: 0.5540 - val_accuracy: 0.7228\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.5194 - accuracy: 0.7399 - val_loss: 0.5484 - val_accuracy: 0.7203\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 2s 230us/step - loss: 0.5173 - accuracy: 0.7392 - val_loss: 0.5446 - val_accuracy: 0.7275\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.5171 - accuracy: 0.7394 - val_loss: 0.5626 - val_accuracy: 0.7203\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 2s 238us/step - loss: 0.5171 - accuracy: 0.7400 - val_loss: 0.5478 - val_accuracy: 0.7208\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 1s 162us/step - loss: 0.5168 - accuracy: 0.7423 - val_loss: 0.5416 - val_accuracy: 0.7275\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 2s 228us/step - loss: 0.5173 - accuracy: 0.7392 - val_loss: 0.5539 - val_accuracy: 0.7157\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 2s 252us/step - loss: 0.5144 - accuracy: 0.7396 - val_loss: 0.5491 - val_accuracy: 0.7177\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 2s 227us/step - loss: 0.5156 - accuracy: 0.7410 - val_loss: 0.5507 - val_accuracy: 0.7213\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 2s 262us/step - loss: 0.5148 - accuracy: 0.7420 - val_loss: 0.5452 - val_accuracy: 0.7208\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5132 - accuracy: 0.7408 - val_loss: 0.5504 - val_accuracy: 0.7254\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 2s 253us/step - loss: 0.5132 - accuracy: 0.7428 - val_loss: 0.5495 - val_accuracy: 0.7249\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 2s 240us/step - loss: 0.5114 - accuracy: 0.7461 - val_loss: 0.5452 - val_accuracy: 0.7254\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 2s 251us/step - loss: 0.5124 - accuracy: 0.7414 - val_loss: 0.5539 - val_accuracy: 0.7182\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 2s 246us/step - loss: 0.5122 - accuracy: 0.7445 - val_loss: 0.5545 - val_accuracy: 0.7218\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 2s 257us/step - loss: 0.5088 - accuracy: 0.7454 - val_loss: 0.5488 - val_accuracy: 0.7213\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5090 - accuracy: 0.7439 - val_loss: 0.5536 - val_accuracy: 0.7203\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 2s 258us/step - loss: 0.5080 - accuracy: 0.7450 - val_loss: 0.5564 - val_accuracy: 0.7100\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 2s 271us/step - loss: 0.5064 - accuracy: 0.7486 - val_loss: 0.5552 - val_accuracy: 0.7223\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5060 - accuracy: 0.7454 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.5049 - accuracy: 0.7472 - val_loss: 0.5572 - val_accuracy: 0.7198\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.5040 - accuracy: 0.7469 - val_loss: 0.5514 - val_accuracy: 0.7239\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 2s 249us/step - loss: 0.5013 - accuracy: 0.7492 - val_loss: 0.5671 - val_accuracy: 0.7182\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.4988 - accuracy: 0.7531 - val_loss: 0.5611 - val_accuracy: 0.7223\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5006 - accuracy: 0.7466 - val_loss: 0.5599 - val_accuracy: 0.7182\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5005 - accuracy: 0.7462 - val_loss: 0.5559 - val_accuracy: 0.7167\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.4994 - accuracy: 0.7524 - val_loss: 0.5641 - val_accuracy: 0.7070\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 2s 262us/step - loss: 0.4979 - accuracy: 0.7492 - val_loss: 0.5688 - val_accuracy: 0.7198\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 2s 248us/step - loss: 0.4949 - accuracy: 0.7539 - val_loss: 0.5747 - val_accuracy: 0.7157\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.4927 - accuracy: 0.7560 - val_loss: 0.5799 - val_accuracy: 0.7054\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 2s 248us/step - loss: 0.4961 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7177\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 2s 252us/step - loss: 0.4920 - accuracy: 0.7526 - val_loss: 0.5734 - val_accuracy: 0.7121\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.4867 - accuracy: 0.7572 - val_loss: 0.5820 - val_accuracy: 0.7065\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.4871 - accuracy: 0.7608 - val_loss: 0.5789 - val_accuracy: 0.7136\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.4855 - accuracy: 0.7579 - val_loss: 0.5964 - val_accuracy: 0.7147\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 2s 277us/step - loss: 0.4806 - accuracy: 0.7614 - val_loss: 0.6283 - val_accuracy: 0.6962\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.4808 - accuracy: 0.7621 - val_loss: 0.5974 - val_accuracy: 0.7054\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.4764 - accuracy: 0.7633 - val_loss: 0.6322 - val_accuracy: 0.7188\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 2s 234us/step - loss: 0.4812 - accuracy: 0.7628 - val_loss: 0.6013 - val_accuracy: 0.6952\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.4756 - accuracy: 0.7643 - val_loss: 0.6295 - val_accuracy: 0.7003\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.4732 - accuracy: 0.7675 - val_loss: 0.6095 - val_accuracy: 0.7080\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.4706 - accuracy: 0.7686 - val_loss: 0.6560 - val_accuracy: 0.7034\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.4716 - accuracy: 0.7704 - val_loss: 0.6075 - val_accuracy: 0.7085\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.4657 - accuracy: 0.7717 - val_loss: 0.6776 - val_accuracy: 0.7003\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.4649 - accuracy: 0.7736 - val_loss: 0.6332 - val_accuracy: 0.7141\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 2s 271us/step - loss: 0.4630 - accuracy: 0.7736 - val_loss: 0.6295 - val_accuracy: 0.7075\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.4589 - accuracy: 0.7775 - val_loss: 0.6824 - val_accuracy: 0.7111\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 2s 254us/step - loss: 0.4616 - accuracy: 0.7802 - val_loss: 0.6334 - val_accuracy: 0.7034\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 2s 257us/step - loss: 0.4552 - accuracy: 0.7785 - val_loss: 0.6430 - val_accuracy: 0.6860\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 2s 259us/step - loss: 0.4517 - accuracy: 0.7800 - val_loss: 0.7079 - val_accuracy: 0.7080\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 2s 248us/step - loss: 0.4553 - accuracy: 0.7755 - val_loss: 0.6709 - val_accuracy: 0.7018\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.4466 - accuracy: 0.7854 - val_loss: 0.7088 - val_accuracy: 0.7070\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 2s 271us/step - loss: 0.4461 - accuracy: 0.7823 - val_loss: 0.7172 - val_accuracy: 0.6988\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 2s 280us/step - loss: 0.4478 - accuracy: 0.7831 - val_loss: 0.6838 - val_accuracy: 0.6849\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.4372 - accuracy: 0.7903 - val_loss: 0.7298 - val_accuracy: 0.6901\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.4434 - accuracy: 0.7862 - val_loss: 0.7148 - val_accuracy: 0.6819\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.4396 - accuracy: 0.7878 - val_loss: 0.6843 - val_accuracy: 0.6880\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.4365 - accuracy: 0.7881 - val_loss: 0.7389 - val_accuracy: 0.7095\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.4313 - accuracy: 0.7948 - val_loss: 0.6971 - val_accuracy: 0.7003\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.4316 - accuracy: 0.7902 - val_loss: 0.7251 - val_accuracy: 0.6983\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.4336 - accuracy: 0.7937 - val_loss: 0.6872 - val_accuracy: 0.6895\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 2s 253us/step - loss: 0.4218 - accuracy: 0.8016 - val_loss: 0.7726 - val_accuracy: 0.6844\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 2s 258us/step - loss: 0.4243 - accuracy: 0.7963 - val_loss: 0.8281 - val_accuracy: 0.6901\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 2s 264us/step - loss: 0.4175 - accuracy: 0.8013 - val_loss: 0.8156 - val_accuracy: 0.6993\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.4150 - accuracy: 0.8053 - val_loss: 0.7644 - val_accuracy: 0.6844\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.4182 - accuracy: 0.8024 - val_loss: 0.8079 - val_accuracy: 0.6942\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 2s 239us/step - loss: 0.4153 - accuracy: 0.8032 - val_loss: 0.7286 - val_accuracy: 0.6988\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 2s 239us/step - loss: 0.4105 - accuracy: 0.8084 - val_loss: 0.8362 - val_accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.4028 - accuracy: 0.8072 - val_loss: 0.8407 - val_accuracy: 0.6885\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.4066 - accuracy: 0.8074 - val_loss: 0.8306 - val_accuracy: 0.6967\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 2s 266us/step - loss: 0.4066 - accuracy: 0.8074 - val_loss: 0.8399 - val_accuracy: 0.6931\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 2s 266us/step - loss: 0.4005 - accuracy: 0.8132 - val_loss: 0.8081 - val_accuracy: 0.6967\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.3983 - accuracy: 0.8123 - val_loss: 0.8597 - val_accuracy: 0.6849\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.4005 - accuracy: 0.8106 - val_loss: 0.8238 - val_accuracy: 0.6798\n"
     ]
    }
   ],
   "source": [
    "history3 = ReluModel3.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ReluModel4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 15,682\n",
      "Trainable params: 15,170\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ReluModel4 = models.Sequential(name='ReluModel4')\n",
    "\n",
    "ReluModel4.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "ReluModel4.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel4.add(layers.BatchNormalization())\n",
    "ReluModel4.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel4.add(layers.BatchNormalization())\n",
    "ReluModel4.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel4.add(layers.BatchNormalization())\n",
    "ReluModel4.add(layers.Dense(64,activation='relu'))\n",
    "ReluModel4.add(layers.BatchNormalization())\n",
    "ReluModel4.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "ReluModel4.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReluModel4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 3s 409us/step - loss: 0.6131 - accuracy: 0.6871 - val_loss: 0.5916 - val_accuracy: 0.6926\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.5570 - accuracy: 0.7119 - val_loss: 0.5550 - val_accuracy: 0.7147\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 3s 336us/step - loss: 0.5570 - accuracy: 0.7155 - val_loss: 0.5535 - val_accuracy: 0.7136\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 3s 336us/step - loss: 0.5447 - accuracy: 0.7216 - val_loss: 0.5480 - val_accuracy: 0.7162\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.5393 - accuracy: 0.7230 - val_loss: 0.5629 - val_accuracy: 0.7193\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 3s 322us/step - loss: 0.5401 - accuracy: 0.7263 - val_loss: 0.5456 - val_accuracy: 0.7228\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.5381 - accuracy: 0.7269 - val_loss: 0.5529 - val_accuracy: 0.7208\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.5328 - accuracy: 0.7295 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 3s 362us/step - loss: 0.5341 - accuracy: 0.7286 - val_loss: 0.5472 - val_accuracy: 0.7244\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 3s 357us/step - loss: 0.5327 - accuracy: 0.7326 - val_loss: 0.5641 - val_accuracy: 0.7080\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.5329 - accuracy: 0.7310 - val_loss: 0.5538 - val_accuracy: 0.7157\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 3s 353us/step - loss: 0.5256 - accuracy: 0.7295 - val_loss: 0.5592 - val_accuracy: 0.7147\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 3s 333us/step - loss: 0.5310 - accuracy: 0.7289 - val_loss: 0.5539 - val_accuracy: 0.7136\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 3s 363us/step - loss: 0.5286 - accuracy: 0.7303 - val_loss: 0.5570 - val_accuracy: 0.7208\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 3s 324us/step - loss: 0.5269 - accuracy: 0.7302 - val_loss: 0.5654 - val_accuracy: 0.7152\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 3s 338us/step - loss: 0.5315 - accuracy: 0.7317 - val_loss: 0.5489 - val_accuracy: 0.7213\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 3s 349us/step - loss: 0.5231 - accuracy: 0.7341 - val_loss: 0.5697 - val_accuracy: 0.7044\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 3s 350us/step - loss: 0.5198 - accuracy: 0.7390 - val_loss: 0.5579 - val_accuracy: 0.7285\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.5205 - accuracy: 0.7316 - val_loss: 0.5604 - val_accuracy: 0.7131\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 3s 365us/step - loss: 0.5211 - accuracy: 0.7385 - val_loss: 0.5564 - val_accuracy: 0.7198\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 3s 344us/step - loss: 0.5228 - accuracy: 0.7384 - val_loss: 0.5516 - val_accuracy: 0.7208\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 3s 347us/step - loss: 0.5100 - accuracy: 0.7443 - val_loss: 0.5550 - val_accuracy: 0.7203\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.5161 - accuracy: 0.7404 - val_loss: 0.5635 - val_accuracy: 0.7147\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 3s 366us/step - loss: 0.5137 - accuracy: 0.7350 - val_loss: 0.5628 - val_accuracy: 0.7106\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5706 - val_accuracy: 0.7177\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 3s 320us/step - loss: 0.5085 - accuracy: 0.7423 - val_loss: 0.5734 - val_accuracy: 0.7090\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 3s 355us/step - loss: 0.5110 - accuracy: 0.7433 - val_loss: 0.5694 - val_accuracy: 0.7167\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.5060 - accuracy: 0.7478 - val_loss: 0.5705 - val_accuracy: 0.7080\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.5054 - accuracy: 0.7445 - val_loss: 0.5794 - val_accuracy: 0.7013\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.5022 - accuracy: 0.7500 - val_loss: 0.5743 - val_accuracy: 0.7049\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 3s 362us/step - loss: 0.5087 - accuracy: 0.7480 - val_loss: 0.5762 - val_accuracy: 0.7090\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.5003 - accuracy: 0.7524 - val_loss: 0.5680 - val_accuracy: 0.7147\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.5001 - accuracy: 0.7556 - val_loss: 0.5741 - val_accuracy: 0.7024\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 3s 326us/step - loss: 0.4941 - accuracy: 0.7564 - val_loss: 0.5898 - val_accuracy: 0.7188\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.4957 - accuracy: 0.7540 - val_loss: 0.5825 - val_accuracy: 0.6972\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.4938 - accuracy: 0.7519 - val_loss: 0.5740 - val_accuracy: 0.7147\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.4960 - accuracy: 0.7580 - val_loss: 0.5766 - val_accuracy: 0.7070\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4922 - accuracy: 0.7584 - val_loss: 0.5753 - val_accuracy: 0.7044\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4911 - accuracy: 0.7591 - val_loss: 0.5827 - val_accuracy: 0.7152\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.4851 - accuracy: 0.7589 - val_loss: 0.5949 - val_accuracy: 0.7024\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 2s 310us/step - loss: 0.4883 - accuracy: 0.7589 - val_loss: 0.5839 - val_accuracy: 0.7193\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 3s 356us/step - loss: 0.4826 - accuracy: 0.7645 - val_loss: 0.6024 - val_accuracy: 0.7044\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.4798 - accuracy: 0.7664 - val_loss: 0.5980 - val_accuracy: 0.6880\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.4807 - accuracy: 0.7669 - val_loss: 0.5996 - val_accuracy: 0.6967\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4721 - accuracy: 0.7728 - val_loss: 0.6031 - val_accuracy: 0.7198\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 3s 331us/step - loss: 0.4731 - accuracy: 0.7709 - val_loss: 0.5948 - val_accuracy: 0.7244\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 3s 318us/step - loss: 0.4726 - accuracy: 0.7665 - val_loss: 0.6041 - val_accuracy: 0.6855\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.4667 - accuracy: 0.7746 - val_loss: 0.6020 - val_accuracy: 0.7075\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 3s 336us/step - loss: 0.4660 - accuracy: 0.7749 - val_loss: 0.6075 - val_accuracy: 0.6972\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.4626 - accuracy: 0.7758 - val_loss: 0.6120 - val_accuracy: 0.7090\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 3s 351us/step - loss: 0.4582 - accuracy: 0.7786 - val_loss: 0.6035 - val_accuracy: 0.6983\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 2s 312us/step - loss: 0.4621 - accuracy: 0.7733 - val_loss: 0.6071 - val_accuracy: 0.6977\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 2s 295us/step - loss: 0.4579 - accuracy: 0.7790 - val_loss: 0.6086 - val_accuracy: 0.6875\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4544 - accuracy: 0.7794 - val_loss: 0.5984 - val_accuracy: 0.7070\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 3s 336us/step - loss: 0.4526 - accuracy: 0.7820 - val_loss: 0.6091 - val_accuracy: 0.6895\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 3s 354us/step - loss: 0.4499 - accuracy: 0.7838 - val_loss: 0.6033 - val_accuracy: 0.7070\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 3s 366us/step - loss: 0.4406 - accuracy: 0.7900 - val_loss: 0.6132 - val_accuracy: 0.7008\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 3s 334us/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.6179 - val_accuracy: 0.7013\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.4430 - accuracy: 0.7850 - val_loss: 0.6222 - val_accuracy: 0.6839\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.4418 - accuracy: 0.7902 - val_loss: 0.6305 - val_accuracy: 0.7039\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 2s 275us/step - loss: 0.4408 - accuracy: 0.7888 - val_loss: 0.6329 - val_accuracy: 0.6921\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.4415 - accuracy: 0.7908 - val_loss: 0.6173 - val_accuracy: 0.6977\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.4370 - accuracy: 0.7931 - val_loss: 0.6327 - val_accuracy: 0.7008\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 3s 331us/step - loss: 0.4331 - accuracy: 0.7935 - val_loss: 0.6193 - val_accuracy: 0.6988\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 3s 336us/step - loss: 0.4283 - accuracy: 0.7963 - val_loss: 0.6489 - val_accuracy: 0.6798\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 3s 323us/step - loss: 0.4264 - accuracy: 0.7983 - val_loss: 0.6436 - val_accuracy: 0.6890\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.4292 - accuracy: 0.7931 - val_loss: 0.6498 - val_accuracy: 0.6844\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4217 - accuracy: 0.8033 - val_loss: 0.6606 - val_accuracy: 0.6911\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.4331 - accuracy: 0.7979 - val_loss: 0.6462 - val_accuracy: 0.7034\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 3s 338us/step - loss: 0.4242 - accuracy: 0.7988 - val_loss: 0.6353 - val_accuracy: 0.7034\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.4240 - accuracy: 0.7979 - val_loss: 0.6405 - val_accuracy: 0.7085\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 3s 343us/step - loss: 0.4169 - accuracy: 0.8057 - val_loss: 0.6532 - val_accuracy: 0.6962\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 3s 354us/step - loss: 0.4186 - accuracy: 0.8055 - val_loss: 0.6478 - val_accuracy: 0.6977\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.4191 - accuracy: 0.8022 - val_loss: 0.6444 - val_accuracy: 0.7013\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 3s 323us/step - loss: 0.4188 - accuracy: 0.8043 - val_loss: 0.6358 - val_accuracy: 0.7157\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 3s 325us/step - loss: 0.4197 - accuracy: 0.7987 - val_loss: 0.6323 - val_accuracy: 0.6947\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 3s 344us/step - loss: 0.4050 - accuracy: 0.8152 - val_loss: 0.6905 - val_accuracy: 0.6819\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 3s 338us/step - loss: 0.4224 - accuracy: 0.8053 - val_loss: 0.6750 - val_accuracy: 0.6983\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 3s 322us/step - loss: 0.4114 - accuracy: 0.8079 - val_loss: 0.6825 - val_accuracy: 0.6880\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 3s 350us/step - loss: 0.4123 - accuracy: 0.8037 - val_loss: 0.6383 - val_accuracy: 0.6998\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 3s 328us/step - loss: 0.4010 - accuracy: 0.8152 - val_loss: 0.6548 - val_accuracy: 0.6855\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 3s 321us/step - loss: 0.4063 - accuracy: 0.8129 - val_loss: 0.6938 - val_accuracy: 0.6624\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 3s 322us/step - loss: 0.4052 - accuracy: 0.8112 - val_loss: 0.6513 - val_accuracy: 0.6849\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.4016 - accuracy: 0.8129 - val_loss: 0.6856 - val_accuracy: 0.6829\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 3s 360us/step - loss: 0.4018 - accuracy: 0.8103 - val_loss: 0.6650 - val_accuracy: 0.6926\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.3969 - accuracy: 0.8158 - val_loss: 0.7003 - val_accuracy: 0.7085\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.3939 - accuracy: 0.8214 - val_loss: 0.6775 - val_accuracy: 0.6895\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.3902 - accuracy: 0.8239 - val_loss: 0.6893 - val_accuracy: 0.6855\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 3s 351us/step - loss: 0.3934 - accuracy: 0.8143 - val_loss: 0.6856 - val_accuracy: 0.6783\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.3877 - accuracy: 0.8216 - val_loss: 0.7340 - val_accuracy: 0.6762\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 3s 349us/step - loss: 0.3863 - accuracy: 0.8215 - val_loss: 0.7102 - val_accuracy: 0.6844\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.3930 - accuracy: 0.8197 - val_loss: 0.7065 - val_accuracy: 0.6798\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 3s 357us/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.6901 - val_accuracy: 0.6936\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.3851 - accuracy: 0.8235 - val_loss: 0.6914 - val_accuracy: 0.6988\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.3858 - accuracy: 0.8238 - val_loss: 0.7289 - val_accuracy: 0.6737\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.3830 - accuracy: 0.8202 - val_loss: 0.7025 - val_accuracy: 0.6942\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.3872 - accuracy: 0.8235 - val_loss: 0.6758 - val_accuracy: 0.6957\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 3s 351us/step - loss: 0.3762 - accuracy: 0.8306 - val_loss: 0.6926 - val_accuracy: 0.6952\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.3851 - accuracy: 0.8241 - val_loss: 0.7080 - val_accuracy: 0.6875\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.3829 - accuracy: 0.8223 - val_loss: 0.7228 - val_accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "history4 = ReluModel4.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SgModel1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,658\n",
      "Trainable params: 14,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SgModel1 = models.Sequential(name='SgModel1')\n",
    "\n",
    "SgModel1.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "SgModel1.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel1.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel1.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel1.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel1.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "SgModel1.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SgModel1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.6652 - accuracy: 0.5752 - val_loss: 0.5615 - val_accuracy: 0.7065\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5445 - accuracy: 0.7251 - val_loss: 0.5414 - val_accuracy: 0.7182\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5358 - accuracy: 0.7278 - val_loss: 0.5400 - val_accuracy: 0.7239\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5378 - accuracy: 0.7260 - val_loss: 0.5473 - val_accuracy: 0.7213\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5334 - accuracy: 0.7342 - val_loss: 0.5391 - val_accuracy: 0.7244\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5349 - accuracy: 0.7341 - val_loss: 0.5412 - val_accuracy: 0.7254\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5370 - accuracy: 0.7302 - val_loss: 0.5383 - val_accuracy: 0.7228\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5364 - accuracy: 0.7318 - val_loss: 0.5388 - val_accuracy: 0.7264\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5358 - accuracy: 0.7309 - val_loss: 0.5427 - val_accuracy: 0.7264\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 2s 196us/step - loss: 0.5354 - accuracy: 0.7314 - val_loss: 0.5386 - val_accuracy: 0.7234\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5328 - accuracy: 0.7308 - val_loss: 0.5414 - val_accuracy: 0.7275\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5334 - accuracy: 0.7308 - val_loss: 0.5384 - val_accuracy: 0.7269\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5331 - accuracy: 0.7293 - val_loss: 0.5374 - val_accuracy: 0.7249\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5328 - accuracy: 0.7318 - val_loss: 0.5550 - val_accuracy: 0.7182\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5323 - accuracy: 0.7286 - val_loss: 0.5389 - val_accuracy: 0.7259\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5321 - accuracy: 0.7310 - val_loss: 0.5441 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5304 - accuracy: 0.7351 - val_loss: 0.5475 - val_accuracy: 0.7254\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5323 - accuracy: 0.7312 - val_loss: 0.5370 - val_accuracy: 0.7239\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5325 - accuracy: 0.7321 - val_loss: 0.5388 - val_accuracy: 0.7239\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5323 - accuracy: 0.7298 - val_loss: 0.5416 - val_accuracy: 0.7264\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5312 - accuracy: 0.7324 - val_loss: 0.5380 - val_accuracy: 0.7254\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5321 - accuracy: 0.7326 - val_loss: 0.5373 - val_accuracy: 0.7239\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5313 - accuracy: 0.7342 - val_loss: 0.5365 - val_accuracy: 0.7239\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 2s 196us/step - loss: 0.5319 - accuracy: 0.7317 - val_loss: 0.5363 - val_accuracy: 0.7223\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 2s 196us/step - loss: 0.5308 - accuracy: 0.7295 - val_loss: 0.5389 - val_accuracy: 0.7264\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5299 - accuracy: 0.7363 - val_loss: 0.5472 - val_accuracy: 0.7188\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5304 - accuracy: 0.7310 - val_loss: 0.5366 - val_accuracy: 0.7239\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5317 - accuracy: 0.7305 - val_loss: 0.5411 - val_accuracy: 0.7259\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 2s 200us/step - loss: 0.5305 - accuracy: 0.7284 - val_loss: 0.5364 - val_accuracy: 0.7223\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5291 - accuracy: 0.7326 - val_loss: 0.5411 - val_accuracy: 0.7239\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5294 - accuracy: 0.7326 - val_loss: 0.5422 - val_accuracy: 0.7234\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5294 - accuracy: 0.7305 - val_loss: 0.5356 - val_accuracy: 0.7234\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5293 - accuracy: 0.7324 - val_loss: 0.5525 - val_accuracy: 0.7198\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5307 - accuracy: 0.7289 - val_loss: 0.5407 - val_accuracy: 0.7218\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5306 - accuracy: 0.7307 - val_loss: 0.5398 - val_accuracy: 0.7249\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5301 - accuracy: 0.7317 - val_loss: 0.5412 - val_accuracy: 0.7218\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5306 - accuracy: 0.7313 - val_loss: 0.5401 - val_accuracy: 0.7269\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5281 - accuracy: 0.7318 - val_loss: 0.5391 - val_accuracy: 0.7275\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5289 - accuracy: 0.7342 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5290 - accuracy: 0.7319 - val_loss: 0.5398 - val_accuracy: 0.7295\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5302 - accuracy: 0.7324 - val_loss: 0.5382 - val_accuracy: 0.7316\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5295 - accuracy: 0.7294 - val_loss: 0.5354 - val_accuracy: 0.7239\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.5287 - accuracy: 0.7327 - val_loss: 0.5406 - val_accuracy: 0.7269\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5275 - accuracy: 0.7353 - val_loss: 0.5451 - val_accuracy: 0.7198\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5292 - accuracy: 0.7313 - val_loss: 0.5361 - val_accuracy: 0.7269\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5290 - accuracy: 0.7331 - val_loss: 0.5360 - val_accuracy: 0.7203\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5292 - accuracy: 0.7309 - val_loss: 0.5364 - val_accuracy: 0.7275\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5292 - accuracy: 0.7331 - val_loss: 0.5507 - val_accuracy: 0.7152\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5284 - accuracy: 0.7312 - val_loss: 0.5360 - val_accuracy: 0.7259\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 1s 161us/step - loss: 0.5309 - accuracy: 0.7372 - val_loss: 0.5421 - val_accuracy: 0.7213\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5285 - accuracy: 0.7309 - val_loss: 0.5385 - val_accuracy: 0.7275\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5287 - accuracy: 0.7324 - val_loss: 0.5374 - val_accuracy: 0.7295\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5277 - accuracy: 0.7322 - val_loss: 0.5406 - val_accuracy: 0.7264\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5301 - accuracy: 0.7297 - val_loss: 0.5363 - val_accuracy: 0.7208\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5291 - accuracy: 0.7319 - val_loss: 0.5364 - val_accuracy: 0.7223\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5284 - accuracy: 0.7337 - val_loss: 0.5374 - val_accuracy: 0.7285\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5286 - accuracy: 0.7342 - val_loss: 0.5355 - val_accuracy: 0.7223\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5284 - accuracy: 0.7322 - val_loss: 0.5435 - val_accuracy: 0.7198\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5270 - accuracy: 0.7327 - val_loss: 0.5384 - val_accuracy: 0.7259\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5288 - accuracy: 0.7302 - val_loss: 0.5436 - val_accuracy: 0.7198\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5268 - accuracy: 0.7342 - val_loss: 0.5384 - val_accuracy: 0.7285\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5275 - accuracy: 0.7338 - val_loss: 0.5361 - val_accuracy: 0.7305\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.5288 - accuracy: 0.7302 - val_loss: 0.5359 - val_accuracy: 0.7295\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5272 - accuracy: 0.7338 - val_loss: 0.5356 - val_accuracy: 0.7239\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5284 - accuracy: 0.7334 - val_loss: 0.5362 - val_accuracy: 0.7218\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5274 - accuracy: 0.7343 - val_loss: 0.5389 - val_accuracy: 0.7234\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5281 - accuracy: 0.7347 - val_loss: 0.5367 - val_accuracy: 0.7295\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 2s 205us/step - loss: 0.5266 - accuracy: 0.7345 - val_loss: 0.5469 - val_accuracy: 0.7213\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 1s 170us/step - loss: 0.5270 - accuracy: 0.7295 - val_loss: 0.5363 - val_accuracy: 0.7223\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5271 - accuracy: 0.7341 - val_loss: 0.5451 - val_accuracy: 0.7213\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5280 - accuracy: 0.7318 - val_loss: 0.5370 - val_accuracy: 0.7249\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5274 - accuracy: 0.7316 - val_loss: 0.5428 - val_accuracy: 0.7264\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5272 - accuracy: 0.7348 - val_loss: 0.5407 - val_accuracy: 0.7254\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5270 - accuracy: 0.7314 - val_loss: 0.5374 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5283 - accuracy: 0.7316 - val_loss: 0.5386 - val_accuracy: 0.7213\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5278 - accuracy: 0.7316 - val_loss: 0.5366 - val_accuracy: 0.7305\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 2s 200us/step - loss: 0.5279 - accuracy: 0.7308 - val_loss: 0.5382 - val_accuracy: 0.7280\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5270 - accuracy: 0.7313 - val_loss: 0.5379 - val_accuracy: 0.7300\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5260 - accuracy: 0.7343 - val_loss: 0.5399 - val_accuracy: 0.7249\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 2s 200us/step - loss: 0.5263 - accuracy: 0.7347 - val_loss: 0.5387 - val_accuracy: 0.7239\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.5268 - accuracy: 0.7337 - val_loss: 0.5377 - val_accuracy: 0.7223\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5271 - accuracy: 0.7337 - val_loss: 0.5361 - val_accuracy: 0.7316\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5264 - accuracy: 0.7341 - val_loss: 0.5360 - val_accuracy: 0.7239\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5264 - accuracy: 0.7337 - val_loss: 0.5364 - val_accuracy: 0.7218\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 2s 189us/step - loss: 0.5261 - accuracy: 0.7345 - val_loss: 0.5373 - val_accuracy: 0.7285\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5276 - accuracy: 0.7323 - val_loss: 0.5364 - val_accuracy: 0.7305\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5254 - accuracy: 0.7346 - val_loss: 0.5367 - val_accuracy: 0.7254\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5260 - accuracy: 0.7331 - val_loss: 0.5378 - val_accuracy: 0.7259\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5268 - accuracy: 0.7339 - val_loss: 0.5389 - val_accuracy: 0.7275\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5257 - accuracy: 0.7332 - val_loss: 0.5401 - val_accuracy: 0.7223\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5267 - accuracy: 0.7348 - val_loss: 0.5383 - val_accuracy: 0.7254\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5262 - accuracy: 0.7312 - val_loss: 0.5476 - val_accuracy: 0.7269\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5277 - accuracy: 0.7295 - val_loss: 0.5410 - val_accuracy: 0.7244\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5267 - accuracy: 0.7332 - val_loss: 0.5402 - val_accuracy: 0.7228\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5258 - accuracy: 0.7332 - val_loss: 0.5365 - val_accuracy: 0.7259\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5255 - accuracy: 0.7338 - val_loss: 0.5422 - val_accuracy: 0.7234\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 2s 189us/step - loss: 0.5251 - accuracy: 0.7326 - val_loss: 0.5384 - val_accuracy: 0.7239\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5252 - accuracy: 0.7342 - val_loss: 0.5375 - val_accuracy: 0.7234\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5269 - accuracy: 0.7365 - val_loss: 0.5409 - val_accuracy: 0.7234\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5252 - accuracy: 0.7336 - val_loss: 0.5379 - val_accuracy: 0.7244\n"
     ]
    }
   ],
   "source": [
    "history5 = SgModel1.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SgModel2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 128)               4096      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 53,890\n",
      "Trainable params: 53,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SgModel2 = models.Sequential(name='SgModel2')\n",
    "\n",
    "SgModel2.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "SgModel2.add(layers.Dense(128,activation='sigmoid'))\n",
    "SgModel2.add(layers.Dense(128,activation='sigmoid'))\n",
    "SgModel2.add(layers.Dense(128,activation='sigmoid'))\n",
    "SgModel2.add(layers.Dense(128,activation='sigmoid'))\n",
    "SgModel2.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "SgModel2.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SgModel2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 2s 212us/step - loss: 0.6299 - accuracy: 0.6203 - val_loss: 0.5468 - val_accuracy: 0.7121\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5445 - accuracy: 0.7237 - val_loss: 0.5391 - val_accuracy: 0.7208\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5382 - accuracy: 0.7252 - val_loss: 0.5475 - val_accuracy: 0.7218\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5371 - accuracy: 0.7268 - val_loss: 0.5389 - val_accuracy: 0.7223\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5366 - accuracy: 0.7303 - val_loss: 0.5715 - val_accuracy: 0.7131\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5338 - accuracy: 0.7274 - val_loss: 0.5446 - val_accuracy: 0.7213\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 1s 166us/step - loss: 0.5339 - accuracy: 0.7290 - val_loss: 0.5407 - val_accuracy: 0.7264\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5366 - accuracy: 0.7292 - val_loss: 0.5369 - val_accuracy: 0.7244\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5349 - accuracy: 0.7304 - val_loss: 0.5384 - val_accuracy: 0.7259\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5321 - accuracy: 0.7317 - val_loss: 0.5407 - val_accuracy: 0.7269\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5348 - accuracy: 0.7312 - val_loss: 0.5395 - val_accuracy: 0.7249\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 2s 206us/step - loss: 0.5319 - accuracy: 0.7323 - val_loss: 0.5442 - val_accuracy: 0.7193\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 2s 199us/step - loss: 0.5360 - accuracy: 0.7234 - val_loss: 0.5469 - val_accuracy: 0.7234\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5353 - accuracy: 0.7266 - val_loss: 0.5382 - val_accuracy: 0.7264\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5328 - accuracy: 0.7281 - val_loss: 0.5393 - val_accuracy: 0.7264\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 2s 208us/step - loss: 0.5340 - accuracy: 0.7252 - val_loss: 0.5450 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5334 - accuracy: 0.7309 - val_loss: 0.5366 - val_accuracy: 0.7264\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5312 - accuracy: 0.7298 - val_loss: 0.5362 - val_accuracy: 0.7264\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 2s 194us/step - loss: 0.5344 - accuracy: 0.7308 - val_loss: 0.5393 - val_accuracy: 0.7239\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5326 - accuracy: 0.7294 - val_loss: 0.5425 - val_accuracy: 0.7223\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5329 - accuracy: 0.7276 - val_loss: 0.5385 - val_accuracy: 0.7198\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5317 - accuracy: 0.7294 - val_loss: 0.5443 - val_accuracy: 0.7198\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5320 - accuracy: 0.7329 - val_loss: 0.5386 - val_accuracy: 0.7203\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5326 - accuracy: 0.7312 - val_loss: 0.5386 - val_accuracy: 0.7316\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 2s 199us/step - loss: 0.5325 - accuracy: 0.7298 - val_loss: 0.5381 - val_accuracy: 0.7223\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 2s 189us/step - loss: 0.5313 - accuracy: 0.7317 - val_loss: 0.5371 - val_accuracy: 0.7244\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5312 - accuracy: 0.7288 - val_loss: 0.5435 - val_accuracy: 0.7239\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5309 - accuracy: 0.7294 - val_loss: 0.5356 - val_accuracy: 0.7239\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5298 - accuracy: 0.7331 - val_loss: 0.5444 - val_accuracy: 0.7203\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 1s 157us/step - loss: 0.5338 - accuracy: 0.7298 - val_loss: 0.5401 - val_accuracy: 0.7177\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 1s 175us/step - loss: 0.5324 - accuracy: 0.7283 - val_loss: 0.5428 - val_accuracy: 0.7193\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5318 - accuracy: 0.7328 - val_loss: 0.5367 - val_accuracy: 0.7259\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5323 - accuracy: 0.7281 - val_loss: 0.5597 - val_accuracy: 0.7172\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5317 - accuracy: 0.7313 - val_loss: 0.5413 - val_accuracy: 0.7310\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5317 - accuracy: 0.7288 - val_loss: 0.5407 - val_accuracy: 0.7285\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5298 - accuracy: 0.7323 - val_loss: 0.5379 - val_accuracy: 0.7193\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.5312 - accuracy: 0.7295 - val_loss: 0.5384 - val_accuracy: 0.7280\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 1s 171us/step - loss: 0.5318 - accuracy: 0.7308 - val_loss: 0.5370 - val_accuracy: 0.7280\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5304 - accuracy: 0.7284 - val_loss: 0.5407 - val_accuracy: 0.7259\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 1s 164us/step - loss: 0.5307 - accuracy: 0.7276 - val_loss: 0.5374 - val_accuracy: 0.7234\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 1s 166us/step - loss: 0.5311 - accuracy: 0.7318 - val_loss: 0.5438 - val_accuracy: 0.7193\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5304 - accuracy: 0.7295 - val_loss: 0.5358 - val_accuracy: 0.7269\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5281 - accuracy: 0.7328 - val_loss: 0.5357 - val_accuracy: 0.7198\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5300 - accuracy: 0.7307 - val_loss: 0.5389 - val_accuracy: 0.7305\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5286 - accuracy: 0.7370 - val_loss: 0.5396 - val_accuracy: 0.7223\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5303 - accuracy: 0.7324 - val_loss: 0.5419 - val_accuracy: 0.7223\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5290 - accuracy: 0.7338 - val_loss: 0.5379 - val_accuracy: 0.7223\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5291 - accuracy: 0.7299 - val_loss: 0.5555 - val_accuracy: 0.7065\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.5286 - accuracy: 0.7312 - val_loss: 0.5358 - val_accuracy: 0.7259\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5294 - accuracy: 0.7307 - val_loss: 0.5356 - val_accuracy: 0.7213\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5299 - accuracy: 0.7324 - val_loss: 0.5366 - val_accuracy: 0.7290\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5286 - accuracy: 0.7328 - val_loss: 0.5351 - val_accuracy: 0.7249\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 2s 203us/step - loss: 0.5285 - accuracy: 0.7336 - val_loss: 0.5404 - val_accuracy: 0.7213\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 1s 174us/step - loss: 0.5291 - accuracy: 0.7357 - val_loss: 0.5376 - val_accuracy: 0.7275\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5300 - accuracy: 0.7298 - val_loss: 0.5372 - val_accuracy: 0.7198\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 1s 178us/step - loss: 0.5275 - accuracy: 0.7345 - val_loss: 0.5375 - val_accuracy: 0.7295\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5280 - accuracy: 0.7319 - val_loss: 0.5459 - val_accuracy: 0.7269\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.5294 - accuracy: 0.7329 - val_loss: 0.5422 - val_accuracy: 0.7218\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 1s 173us/step - loss: 0.5282 - accuracy: 0.7316 - val_loss: 0.5388 - val_accuracy: 0.7341\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 1s 188us/step - loss: 0.5288 - accuracy: 0.7307 - val_loss: 0.5416 - val_accuracy: 0.7234\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5289 - accuracy: 0.7316 - val_loss: 0.5379 - val_accuracy: 0.7203\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 1s 189us/step - loss: 0.5288 - accuracy: 0.7324 - val_loss: 0.5373 - val_accuracy: 0.7244\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5276 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7213\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 2s 193us/step - loss: 0.5299 - accuracy: 0.7337 - val_loss: 0.5370 - val_accuracy: 0.7295\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 2s 199us/step - loss: 0.5277 - accuracy: 0.7307 - val_loss: 0.5433 - val_accuracy: 0.7234\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 1s 177us/step - loss: 0.5280 - accuracy: 0.7326 - val_loss: 0.5383 - val_accuracy: 0.7249\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 2s 200us/step - loss: 0.5270 - accuracy: 0.7334 - val_loss: 0.5399 - val_accuracy: 0.7218\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5263 - accuracy: 0.7347 - val_loss: 0.5366 - val_accuracy: 0.7239\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5273 - accuracy: 0.7313 - val_loss: 0.5380 - val_accuracy: 0.7249\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5278 - accuracy: 0.7332 - val_loss: 0.5372 - val_accuracy: 0.7254\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5260 - accuracy: 0.7324 - val_loss: 0.5386 - val_accuracy: 0.7234\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 2s 201us/step - loss: 0.5269 - accuracy: 0.7339 - val_loss: 0.5382 - val_accuracy: 0.7275\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 2s 201us/step - loss: 0.5276 - accuracy: 0.7327 - val_loss: 0.5379 - val_accuracy: 0.7285\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 2s 204us/step - loss: 0.5264 - accuracy: 0.7309 - val_loss: 0.5417 - val_accuracy: 0.7239\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5261 - accuracy: 0.7352 - val_loss: 0.5362 - val_accuracy: 0.7223\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 1s 186us/step - loss: 0.5279 - accuracy: 0.7326 - val_loss: 0.5480 - val_accuracy: 0.7208\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 2s 198us/step - loss: 0.5272 - accuracy: 0.7308 - val_loss: 0.5375 - val_accuracy: 0.7228\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 1s 184us/step - loss: 0.5261 - accuracy: 0.7327 - val_loss: 0.5371 - val_accuracy: 0.7234\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5267 - accuracy: 0.7356 - val_loss: 0.5465 - val_accuracy: 0.7264\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5267 - accuracy: 0.7318 - val_loss: 0.5367 - val_accuracy: 0.7223\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 1s 181us/step - loss: 0.5260 - accuracy: 0.7343 - val_loss: 0.5397 - val_accuracy: 0.7223\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 1s 171us/step - loss: 0.5272 - accuracy: 0.7326 - val_loss: 0.5419 - val_accuracy: 0.7269\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 1s 171us/step - loss: 0.5250 - accuracy: 0.7333 - val_loss: 0.5383 - val_accuracy: 0.7264\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 2s 195us/step - loss: 0.5248 - accuracy: 0.7352 - val_loss: 0.5389 - val_accuracy: 0.7239\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5248 - accuracy: 0.7328 - val_loss: 0.5381 - val_accuracy: 0.7264\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5258 - accuracy: 0.7322 - val_loss: 0.5431 - val_accuracy: 0.7223\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 2s 192us/step - loss: 0.5260 - accuracy: 0.7309 - val_loss: 0.5389 - val_accuracy: 0.7290\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 2s 210us/step - loss: 0.5257 - accuracy: 0.7360 - val_loss: 0.5385 - val_accuracy: 0.7259\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 2s 191us/step - loss: 0.5261 - accuracy: 0.7326 - val_loss: 0.5468 - val_accuracy: 0.7198\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5261 - accuracy: 0.7322 - val_loss: 0.5465 - val_accuracy: 0.7228\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5257 - accuracy: 0.7336 - val_loss: 0.5399 - val_accuracy: 0.7249\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 2s 196us/step - loss: 0.5249 - accuracy: 0.7336 - val_loss: 0.5380 - val_accuracy: 0.7269\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 1s 180us/step - loss: 0.5252 - accuracy: 0.7347 - val_loss: 0.5394 - val_accuracy: 0.7269\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 1s 187us/step - loss: 0.5256 - accuracy: 0.7326 - val_loss: 0.5426 - val_accuracy: 0.7269\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 1s 183us/step - loss: 0.5254 - accuracy: 0.7333 - val_loss: 0.5390 - val_accuracy: 0.7264\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 2s 197us/step - loss: 0.5247 - accuracy: 0.7362 - val_loss: 0.5381 - val_accuracy: 0.7239\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 1s 185us/step - loss: 0.5250 - accuracy: 0.7332 - val_loss: 0.5425 - val_accuracy: 0.7249\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 1s 176us/step - loss: 0.5249 - accuracy: 0.7339 - val_loss: 0.5417 - val_accuracy: 0.7269\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 1s 182us/step - loss: 0.5245 - accuracy: 0.7321 - val_loss: 0.5413 - val_accuracy: 0.7244\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 2s 190us/step - loss: 0.5251 - accuracy: 0.7357 - val_loss: 0.5389 - val_accuracy: 0.7223\n"
     ]
    }
   ],
   "source": [
    "history6 = SgModel2.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SgModel3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 19,842\n",
      "Trainable params: 19,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SgModel3 = models.Sequential(name='SgModel3')\n",
    "\n",
    "SgModel3.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "SgModel3.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(32,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(32,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(32,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(32,activation='sigmoid'))\n",
    "SgModel3.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "SgModel3.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SgModel3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 2s 293us/step - loss: 0.6977 - accuracy: 0.4965 - val_loss: 0.6935 - val_accuracy: 0.5077\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 2s 255us/step - loss: 0.6703 - accuracy: 0.5784 - val_loss: 0.5925 - val_accuracy: 0.7065\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.5764 - accuracy: 0.7215 - val_loss: 0.5698 - val_accuracy: 0.7188\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.5543 - accuracy: 0.7275 - val_loss: 0.5610 - val_accuracy: 0.7198\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 2s 278us/step - loss: 0.5440 - accuracy: 0.7310 - val_loss: 0.5539 - val_accuracy: 0.7223\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5383 - accuracy: 0.7312 - val_loss: 0.5431 - val_accuracy: 0.7249\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 2s 259us/step - loss: 0.5371 - accuracy: 0.7278 - val_loss: 0.5387 - val_accuracy: 0.7234\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 2s 254us/step - loss: 0.5363 - accuracy: 0.7265 - val_loss: 0.5387 - val_accuracy: 0.7234\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 2s 254us/step - loss: 0.5368 - accuracy: 0.7251 - val_loss: 0.5401 - val_accuracy: 0.7244\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.5350 - accuracy: 0.7312 - val_loss: 0.5417 - val_accuracy: 0.7244\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 2s 280us/step - loss: 0.5379 - accuracy: 0.7259 - val_loss: 0.5456 - val_accuracy: 0.7223\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.5316 - accuracy: 0.7284 - val_loss: 0.5381 - val_accuracy: 0.7244\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 2s 278us/step - loss: 0.5326 - accuracy: 0.7283 - val_loss: 0.5393 - val_accuracy: 0.7254\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 2s 278us/step - loss: 0.5315 - accuracy: 0.7294 - val_loss: 0.5411 - val_accuracy: 0.7295\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 2s 291us/step - loss: 0.5328 - accuracy: 0.7302 - val_loss: 0.5387 - val_accuracy: 0.7269\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 2s 273us/step - loss: 0.5331 - accuracy: 0.7288 - val_loss: 0.5405 - val_accuracy: 0.7259\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 2s 275us/step - loss: 0.5328 - accuracy: 0.7292 - val_loss: 0.5428 - val_accuracy: 0.7254\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.5324 - accuracy: 0.7313 - val_loss: 0.5454 - val_accuracy: 0.7193\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 2s 277us/step - loss: 0.5347 - accuracy: 0.7286 - val_loss: 0.5439 - val_accuracy: 0.7234\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 2s 275us/step - loss: 0.5341 - accuracy: 0.7316 - val_loss: 0.5378 - val_accuracy: 0.7249\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5320 - accuracy: 0.7324 - val_loss: 0.5424 - val_accuracy: 0.7259\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 2s 284us/step - loss: 0.5324 - accuracy: 0.7289 - val_loss: 0.5378 - val_accuracy: 0.7249\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.5336 - accuracy: 0.7288 - val_loss: 0.5436 - val_accuracy: 0.7259\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 2s 289us/step - loss: 0.5312 - accuracy: 0.7309 - val_loss: 0.5373 - val_accuracy: 0.7234\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 2s 268us/step - loss: 0.5304 - accuracy: 0.7303 - val_loss: 0.5425 - val_accuracy: 0.7244\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 2s 277us/step - loss: 0.5311 - accuracy: 0.7304 - val_loss: 0.5382 - val_accuracy: 0.7244\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5325 - accuracy: 0.7308 - val_loss: 0.5376 - val_accuracy: 0.7280\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 2s 285us/step - loss: 0.5317 - accuracy: 0.7284 - val_loss: 0.5373 - val_accuracy: 0.7223\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 2s 284us/step - loss: 0.5316 - accuracy: 0.7304 - val_loss: 0.5381 - val_accuracy: 0.7264\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5324 - accuracy: 0.7279 - val_loss: 0.5380 - val_accuracy: 0.7244\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 2s 277us/step - loss: 0.5321 - accuracy: 0.7288 - val_loss: 0.5382 - val_accuracy: 0.7269\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 2s 285us/step - loss: 0.5311 - accuracy: 0.7314 - val_loss: 0.5370 - val_accuracy: 0.7259\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5327 - accuracy: 0.7322 - val_loss: 0.5442 - val_accuracy: 0.7259\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.5323 - accuracy: 0.7312 - val_loss: 0.5399 - val_accuracy: 0.7198\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 2s 288us/step - loss: 0.5306 - accuracy: 0.7305 - val_loss: 0.5373 - val_accuracy: 0.7254\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 2s 271us/step - loss: 0.5298 - accuracy: 0.7355 - val_loss: 0.5380 - val_accuracy: 0.7223\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 2s 283us/step - loss: 0.5310 - accuracy: 0.7323 - val_loss: 0.5472 - val_accuracy: 0.7193\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.5314 - accuracy: 0.7281 - val_loss: 0.5414 - val_accuracy: 0.7244\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 2s 261us/step - loss: 0.5310 - accuracy: 0.7310 - val_loss: 0.5425 - val_accuracy: 0.7295\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 2s 262us/step - loss: 0.5302 - accuracy: 0.7321 - val_loss: 0.5406 - val_accuracy: 0.7269\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 1s 179us/step - loss: 0.5299 - accuracy: 0.7318 - val_loss: 0.5474 - val_accuracy: 0.7203\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 2s 208us/step - loss: 0.5314 - accuracy: 0.7324 - val_loss: 0.5367 - val_accuracy: 0.7213\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 2s 236us/step - loss: 0.5304 - accuracy: 0.7289 - val_loss: 0.5390 - val_accuracy: 0.7234\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 2s 204us/step - loss: 0.5314 - accuracy: 0.7312 - val_loss: 0.5449 - val_accuracy: 0.7208\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 2s 222us/step - loss: 0.5293 - accuracy: 0.7281 - val_loss: 0.5439 - val_accuracy: 0.7198\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 2s 254us/step - loss: 0.5313 - accuracy: 0.7281 - val_loss: 0.5369 - val_accuracy: 0.7193\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 2s 254us/step - loss: 0.5314 - accuracy: 0.7294 - val_loss: 0.5408 - val_accuracy: 0.7213\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 2s 267us/step - loss: 0.5311 - accuracy: 0.7317 - val_loss: 0.5370 - val_accuracy: 0.7213\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 2s 259us/step - loss: 0.5305 - accuracy: 0.7333 - val_loss: 0.5392 - val_accuracy: 0.7300\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 2s 255us/step - loss: 0.5300 - accuracy: 0.7305 - val_loss: 0.5375 - val_accuracy: 0.7213\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5306 - accuracy: 0.7281 - val_loss: 0.5365 - val_accuracy: 0.7244\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 2s 247us/step - loss: 0.5295 - accuracy: 0.7304 - val_loss: 0.5388 - val_accuracy: 0.7208\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 2s 275us/step - loss: 0.5301 - accuracy: 0.7323 - val_loss: 0.5400 - val_accuracy: 0.7213\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 2s 273us/step - loss: 0.5308 - accuracy: 0.7342 - val_loss: 0.5386 - val_accuracy: 0.7223\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 2s 281us/step - loss: 0.5313 - accuracy: 0.7290 - val_loss: 0.5426 - val_accuracy: 0.7239\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5305 - accuracy: 0.7338 - val_loss: 0.5372 - val_accuracy: 0.7203\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 2s 283us/step - loss: 0.5303 - accuracy: 0.7355 - val_loss: 0.5450 - val_accuracy: 0.7310\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 2s 282us/step - loss: 0.5315 - accuracy: 0.7278 - val_loss: 0.5404 - val_accuracy: 0.7300\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.5298 - accuracy: 0.7341 - val_loss: 0.5399 - val_accuracy: 0.7275\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 2s 266us/step - loss: 0.5309 - accuracy: 0.7332 - val_loss: 0.5386 - val_accuracy: 0.7310\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 2s 286us/step - loss: 0.5294 - accuracy: 0.7365 - val_loss: 0.5430 - val_accuracy: 0.7223\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 2s 283us/step - loss: 0.5295 - accuracy: 0.7339 - val_loss: 0.5403 - val_accuracy: 0.7285\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 2s 263us/step - loss: 0.5291 - accuracy: 0.7316 - val_loss: 0.5412 - val_accuracy: 0.7208\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 2s 252us/step - loss: 0.5298 - accuracy: 0.7319 - val_loss: 0.5425 - val_accuracy: 0.7228\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5301 - accuracy: 0.7318 - val_loss: 0.5397 - val_accuracy: 0.7218\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 2s 257us/step - loss: 0.5279 - accuracy: 0.7324 - val_loss: 0.5387 - val_accuracy: 0.7275\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 2s 289us/step - loss: 0.5297 - accuracy: 0.7308 - val_loss: 0.5380 - val_accuracy: 0.7208\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 2s 258us/step - loss: 0.5292 - accuracy: 0.7328 - val_loss: 0.5366 - val_accuracy: 0.7249\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 2s 269us/step - loss: 0.5281 - accuracy: 0.7339 - val_loss: 0.5391 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5292 - accuracy: 0.7351 - val_loss: 0.5393 - val_accuracy: 0.7275\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 2s 280us/step - loss: 0.5291 - accuracy: 0.7324 - val_loss: 0.5519 - val_accuracy: 0.7193\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5286 - accuracy: 0.7302 - val_loss: 0.5370 - val_accuracy: 0.7193\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 2s 270us/step - loss: 0.5300 - accuracy: 0.7328 - val_loss: 0.5403 - val_accuracy: 0.7182\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 2s 272us/step - loss: 0.5283 - accuracy: 0.7332 - val_loss: 0.5396 - val_accuracy: 0.7295\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 2s 271us/step - loss: 0.5302 - accuracy: 0.7313 - val_loss: 0.5383 - val_accuracy: 0.7290\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5281 - accuracy: 0.7351 - val_loss: 0.5394 - val_accuracy: 0.7249\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 2s 285us/step - loss: 0.5277 - accuracy: 0.7329 - val_loss: 0.5390 - val_accuracy: 0.7218\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 2s 274us/step - loss: 0.5282 - accuracy: 0.7347 - val_loss: 0.5518 - val_accuracy: 0.7193\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 2s 275us/step - loss: 0.5290 - accuracy: 0.7322 - val_loss: 0.5459 - val_accuracy: 0.7275\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5281 - accuracy: 0.7323 - val_loss: 0.5387 - val_accuracy: 0.7218\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 2s 284us/step - loss: 0.5280 - accuracy: 0.7323 - val_loss: 0.5402 - val_accuracy: 0.7234\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5316 - accuracy: 0.7302 - val_loss: 0.5403 - val_accuracy: 0.7259\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 2s 266us/step - loss: 0.5286 - accuracy: 0.7322 - val_loss: 0.5377 - val_accuracy: 0.7259\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5274 - accuracy: 0.7302 - val_loss: 0.5411 - val_accuracy: 0.7239\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5274 - accuracy: 0.7343 - val_loss: 0.5444 - val_accuracy: 0.7300\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 2s 265us/step - loss: 0.5271 - accuracy: 0.7331 - val_loss: 0.5455 - val_accuracy: 0.7264\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 2s 246us/step - loss: 0.5291 - accuracy: 0.7334 - val_loss: 0.5395 - val_accuracy: 0.7295\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 2s 239us/step - loss: 0.5271 - accuracy: 0.7338 - val_loss: 0.5373 - val_accuracy: 0.7234\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 2s 264us/step - loss: 0.5280 - accuracy: 0.7312 - val_loss: 0.5459 - val_accuracy: 0.7234\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 2s 278us/step - loss: 0.5280 - accuracy: 0.7278 - val_loss: 0.5404 - val_accuracy: 0.7264\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 2s 276us/step - loss: 0.5281 - accuracy: 0.7324 - val_loss: 0.5390 - val_accuracy: 0.7280\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 2s 257us/step - loss: 0.5274 - accuracy: 0.7342 - val_loss: 0.5487 - val_accuracy: 0.7198\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 2s 261us/step - loss: 0.5273 - accuracy: 0.7334 - val_loss: 0.5396 - val_accuracy: 0.7244\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 2s 253us/step - loss: 0.5268 - accuracy: 0.7309 - val_loss: 0.5400 - val_accuracy: 0.7218\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 2s 266us/step - loss: 0.5265 - accuracy: 0.7341 - val_loss: 0.5391 - val_accuracy: 0.7254\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 2s 260us/step - loss: 0.5270 - accuracy: 0.7342 - val_loss: 0.5424 - val_accuracy: 0.7244\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 2s 262us/step - loss: 0.5269 - accuracy: 0.7319 - val_loss: 0.5430 - val_accuracy: 0.7259\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 2s 252us/step - loss: 0.5274 - accuracy: 0.7319 - val_loss: 0.5452 - val_accuracy: 0.7244\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 2s 259us/step - loss: 0.5272 - accuracy: 0.7328 - val_loss: 0.5429 - val_accuracy: 0.7254\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 2s 255us/step - loss: 0.5277 - accuracy: 0.7326 - val_loss: 0.5471 - val_accuracy: 0.7213\n"
     ]
    }
   ],
   "source": [
    "history7 = SgModel3.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SgModel4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 15,682\n",
      "Trainable params: 15,170\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SgModel4 = models.Sequential(name='SgModel4')\n",
    "\n",
    "SgModel4.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "SgModel4.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel4.add(layers.BatchNormalization())\n",
    "SgModel4.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel4.add(layers.BatchNormalization())\n",
    "SgModel4.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel4.add(layers.BatchNormalization())\n",
    "SgModel4.add(layers.Dense(64,activation='sigmoid'))\n",
    "SgModel4.add(layers.BatchNormalization())\n",
    "SgModel4.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "SgModel4.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SgModel4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7927 samples, validate on 1952 samples\n",
      "Epoch 1/100\n",
      "7927/7927 [==============================] - 3s 396us/step - loss: 0.5805 - accuracy: 0.7059 - val_loss: 0.6732 - val_accuracy: 0.7049\n",
      "Epoch 2/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.5513 - accuracy: 0.7153 - val_loss: 0.5654 - val_accuracy: 0.7193\n",
      "Epoch 3/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.5445 - accuracy: 0.7231 - val_loss: 0.5646 - val_accuracy: 0.7029\n",
      "Epoch 4/100\n",
      "7927/7927 [==============================] - 3s 376us/step - loss: 0.5434 - accuracy: 0.7231 - val_loss: 0.5547 - val_accuracy: 0.7131\n",
      "Epoch 5/100\n",
      "7927/7927 [==============================] - 3s 321us/step - loss: 0.5446 - accuracy: 0.7192 - val_loss: 0.5467 - val_accuracy: 0.7285\n",
      "Epoch 6/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.5436 - accuracy: 0.7227 - val_loss: 0.5597 - val_accuracy: 0.7100\n",
      "Epoch 7/100\n",
      "7927/7927 [==============================] - 3s 356us/step - loss: 0.5402 - accuracy: 0.7226 - val_loss: 0.5479 - val_accuracy: 0.7203\n",
      "Epoch 8/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.5371 - accuracy: 0.7213 - val_loss: 0.5569 - val_accuracy: 0.7095\n",
      "Epoch 9/100\n",
      "7927/7927 [==============================] - 3s 322us/step - loss: 0.5418 - accuracy: 0.7213 - val_loss: 0.5483 - val_accuracy: 0.7193\n",
      "Epoch 10/100\n",
      "7927/7927 [==============================] - 3s 353us/step - loss: 0.5397 - accuracy: 0.7220 - val_loss: 0.5463 - val_accuracy: 0.7234\n",
      "Epoch 11/100\n",
      "7927/7927 [==============================] - 3s 350us/step - loss: 0.5358 - accuracy: 0.7230 - val_loss: 0.5430 - val_accuracy: 0.7280\n",
      "Epoch 12/100\n",
      "7927/7927 [==============================] - 3s 350us/step - loss: 0.5377 - accuracy: 0.7220 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 13/100\n",
      "7927/7927 [==============================] - 3s 353us/step - loss: 0.5348 - accuracy: 0.7266 - val_loss: 0.5484 - val_accuracy: 0.7218\n",
      "Epoch 14/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.5332 - accuracy: 0.7324 - val_loss: 0.5612 - val_accuracy: 0.7100\n",
      "Epoch 15/100\n",
      "7927/7927 [==============================] - 3s 342us/step - loss: 0.5371 - accuracy: 0.7276 - val_loss: 0.5456 - val_accuracy: 0.7239\n",
      "Epoch 16/100\n",
      "7927/7927 [==============================] - 2s 279us/step - loss: 0.5368 - accuracy: 0.7211 - val_loss: 0.5500 - val_accuracy: 0.7106\n",
      "Epoch 17/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.5315 - accuracy: 0.7246 - val_loss: 0.5675 - val_accuracy: 0.6865\n",
      "Epoch 18/100\n",
      "7927/7927 [==============================] - 3s 326us/step - loss: 0.5333 - accuracy: 0.7316 - val_loss: 0.5584 - val_accuracy: 0.7162\n",
      "Epoch 19/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.5341 - accuracy: 0.7308 - val_loss: 0.5512 - val_accuracy: 0.7208\n",
      "Epoch 20/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.5310 - accuracy: 0.7278 - val_loss: 0.5571 - val_accuracy: 0.7131\n",
      "Epoch 21/100\n",
      "7927/7927 [==============================] - 3s 359us/step - loss: 0.5355 - accuracy: 0.7246 - val_loss: 0.5440 - val_accuracy: 0.7259\n",
      "Epoch 22/100\n",
      "7927/7927 [==============================] - 2s 292us/step - loss: 0.5301 - accuracy: 0.7314 - val_loss: 0.5559 - val_accuracy: 0.7111\n",
      "Epoch 23/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.5263 - accuracy: 0.7334 - val_loss: 0.5518 - val_accuracy: 0.7116\n",
      "Epoch 24/100\n",
      "7927/7927 [==============================] - 3s 357us/step - loss: 0.5288 - accuracy: 0.7292 - val_loss: 0.5483 - val_accuracy: 0.7223\n",
      "Epoch 25/100\n",
      "7927/7927 [==============================] - 3s 356us/step - loss: 0.5237 - accuracy: 0.7357 - val_loss: 0.5490 - val_accuracy: 0.7244\n",
      "Epoch 26/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.5277 - accuracy: 0.7336 - val_loss: 0.5458 - val_accuracy: 0.7275\n",
      "Epoch 27/100\n",
      "7927/7927 [==============================] - 3s 363us/step - loss: 0.5299 - accuracy: 0.7327 - val_loss: 0.5470 - val_accuracy: 0.7198\n",
      "Epoch 28/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.5264 - accuracy: 0.7370 - val_loss: 0.5507 - val_accuracy: 0.7177\n",
      "Epoch 29/100\n",
      "7927/7927 [==============================] - 3s 358us/step - loss: 0.5243 - accuracy: 0.7348 - val_loss: 0.5461 - val_accuracy: 0.7275\n",
      "Epoch 30/100\n",
      "7927/7927 [==============================] - 3s 360us/step - loss: 0.5251 - accuracy: 0.7352 - val_loss: 0.5486 - val_accuracy: 0.7106\n",
      "Epoch 31/100\n",
      "7927/7927 [==============================] - 3s 344us/step - loss: 0.5262 - accuracy: 0.7366 - val_loss: 0.5496 - val_accuracy: 0.7193\n",
      "Epoch 32/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.5203 - accuracy: 0.7374 - val_loss: 0.5553 - val_accuracy: 0.7188\n",
      "Epoch 33/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.5210 - accuracy: 0.7396 - val_loss: 0.5516 - val_accuracy: 0.7126\n",
      "Epoch 34/100\n",
      "7927/7927 [==============================] - 2s 313us/step - loss: 0.5226 - accuracy: 0.7403 - val_loss: 0.5534 - val_accuracy: 0.7203\n",
      "Epoch 35/100\n",
      "7927/7927 [==============================] - 3s 320us/step - loss: 0.5229 - accuracy: 0.7357 - val_loss: 0.5486 - val_accuracy: 0.7152\n",
      "Epoch 36/100\n",
      "7927/7927 [==============================] - 3s 356us/step - loss: 0.5165 - accuracy: 0.7400 - val_loss: 0.5541 - val_accuracy: 0.7188\n",
      "Epoch 37/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.5189 - accuracy: 0.7415 - val_loss: 0.5567 - val_accuracy: 0.7065\n",
      "Epoch 38/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.5159 - accuracy: 0.7427 - val_loss: 0.5595 - val_accuracy: 0.7039\n",
      "Epoch 39/100\n",
      "7927/7927 [==============================] - 3s 330us/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5546 - val_accuracy: 0.7121\n",
      "Epoch 40/100\n",
      "7927/7927 [==============================] - 3s 350us/step - loss: 0.5205 - accuracy: 0.7352 - val_loss: 0.5499 - val_accuracy: 0.7167\n",
      "Epoch 41/100\n",
      "7927/7927 [==============================] - 3s 355us/step - loss: 0.5114 - accuracy: 0.7427 - val_loss: 0.5640 - val_accuracy: 0.7157\n",
      "Epoch 42/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.5117 - accuracy: 0.7492 - val_loss: 0.5545 - val_accuracy: 0.7126\n",
      "Epoch 43/100\n",
      "7927/7927 [==============================] - 3s 338us/step - loss: 0.5061 - accuracy: 0.7478 - val_loss: 0.5744 - val_accuracy: 0.7100\n",
      "Epoch 44/100\n",
      "7927/7927 [==============================] - 3s 349us/step - loss: 0.5094 - accuracy: 0.7506 - val_loss: 0.5638 - val_accuracy: 0.7141\n",
      "Epoch 45/100\n",
      "7927/7927 [==============================] - 3s 343us/step - loss: 0.5023 - accuracy: 0.7507 - val_loss: 0.5608 - val_accuracy: 0.7116\n",
      "Epoch 46/100\n",
      "7927/7927 [==============================] - 2s 285us/step - loss: 0.5049 - accuracy: 0.7525 - val_loss: 0.5669 - val_accuracy: 0.7034\n",
      "Epoch 47/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.5067 - accuracy: 0.7481 - val_loss: 0.5572 - val_accuracy: 0.7141\n",
      "Epoch 48/100\n",
      "7927/7927 [==============================] - 3s 326us/step - loss: 0.5030 - accuracy: 0.7493 - val_loss: 0.5798 - val_accuracy: 0.6942\n",
      "Epoch 49/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.4998 - accuracy: 0.7591 - val_loss: 0.5613 - val_accuracy: 0.7131\n",
      "Epoch 50/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.5022 - accuracy: 0.7472 - val_loss: 0.5578 - val_accuracy: 0.7131\n",
      "Epoch 51/100\n",
      "7927/7927 [==============================] - 3s 330us/step - loss: 0.4928 - accuracy: 0.7608 - val_loss: 0.5795 - val_accuracy: 0.7152\n",
      "Epoch 52/100\n",
      "7927/7927 [==============================] - 3s 347us/step - loss: 0.4932 - accuracy: 0.7561 - val_loss: 0.5677 - val_accuracy: 0.7054\n",
      "Epoch 53/100\n",
      "7927/7927 [==============================] - 3s 334us/step - loss: 0.4928 - accuracy: 0.7549 - val_loss: 0.5801 - val_accuracy: 0.7080\n",
      "Epoch 54/100\n",
      "7927/7927 [==============================] - 3s 357us/step - loss: 0.4885 - accuracy: 0.7614 - val_loss: 0.5724 - val_accuracy: 0.7034\n",
      "Epoch 55/100\n",
      "7927/7927 [==============================] - 3s 318us/step - loss: 0.4881 - accuracy: 0.7602 - val_loss: 0.5754 - val_accuracy: 0.7111\n",
      "Epoch 56/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.4930 - accuracy: 0.7569 - val_loss: 0.5758 - val_accuracy: 0.7075\n",
      "Epoch 57/100\n",
      "7927/7927 [==============================] - 3s 355us/step - loss: 0.4883 - accuracy: 0.7594 - val_loss: 0.5739 - val_accuracy: 0.7136\n",
      "Epoch 58/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.4836 - accuracy: 0.7637 - val_loss: 0.5930 - val_accuracy: 0.6947\n",
      "Epoch 59/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.4792 - accuracy: 0.7679 - val_loss: 0.5928 - val_accuracy: 0.7003s:\n",
      "Epoch 60/100\n",
      "7927/7927 [==============================] - 3s 330us/step - loss: 0.4800 - accuracy: 0.7646 - val_loss: 0.5806 - val_accuracy: 0.6988\n",
      "Epoch 61/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.4769 - accuracy: 0.7681 - val_loss: 0.5886 - val_accuracy: 0.7111\n",
      "Epoch 62/100\n",
      "7927/7927 [==============================] - 3s 361us/step - loss: 0.4744 - accuracy: 0.7679 - val_loss: 0.5854 - val_accuracy: 0.7085\n",
      "Epoch 63/100\n",
      "7927/7927 [==============================] - 3s 354us/step - loss: 0.4764 - accuracy: 0.7661 - val_loss: 0.5952 - val_accuracy: 0.7039\n",
      "Epoch 64/100\n",
      "7927/7927 [==============================] - 3s 368us/step - loss: 0.4726 - accuracy: 0.7739 - val_loss: 0.5855 - val_accuracy: 0.7121\n",
      "Epoch 65/100\n",
      "7927/7927 [==============================] - 3s 368us/step - loss: 0.4664 - accuracy: 0.7756 - val_loss: 0.5863 - val_accuracy: 0.6998\n",
      "Epoch 66/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.4638 - accuracy: 0.7799 - val_loss: 0.5887 - val_accuracy: 0.7003\n",
      "Epoch 67/100\n",
      "7927/7927 [==============================] - 3s 351us/step - loss: 0.4642 - accuracy: 0.7791 - val_loss: 0.5964 - val_accuracy: 0.6993\n",
      "Epoch 68/100\n",
      "7927/7927 [==============================] - 3s 348us/step - loss: 0.4608 - accuracy: 0.7811 - val_loss: 0.6013 - val_accuracy: 0.6926\n",
      "Epoch 69/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.4551 - accuracy: 0.7834 - val_loss: 0.6187 - val_accuracy: 0.6972\n",
      "Epoch 70/100\n",
      "7927/7927 [==============================] - 3s 326us/step - loss: 0.4581 - accuracy: 0.7818 - val_loss: 0.6103 - val_accuracy: 0.6988\n",
      "Epoch 71/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.4542 - accuracy: 0.7839 - val_loss: 0.6158 - val_accuracy: 0.7008\n",
      "Epoch 72/100\n",
      "7927/7927 [==============================] - 3s 353us/step - loss: 0.4568 - accuracy: 0.7819 - val_loss: 0.6103 - val_accuracy: 0.6967\n",
      "Epoch 73/100\n",
      "7927/7927 [==============================] - 3s 352us/step - loss: 0.4505 - accuracy: 0.7858 - val_loss: 0.6209 - val_accuracy: 0.6947\n",
      "Epoch 74/100\n",
      "7927/7927 [==============================] - 3s 334us/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.6307 - val_accuracy: 0.6885\n",
      "Epoch 75/100\n",
      "7927/7927 [==============================] - 3s 341us/step - loss: 0.4446 - accuracy: 0.7868 - val_loss: 0.6031 - val_accuracy: 0.7044\n",
      "Epoch 76/100\n",
      "7927/7927 [==============================] - 3s 353us/step - loss: 0.4390 - accuracy: 0.7960 - val_loss: 0.6212 - val_accuracy: 0.6977\n",
      "Epoch 77/100\n",
      "7927/7927 [==============================] - 3s 349us/step - loss: 0.4444 - accuracy: 0.7869 - val_loss: 0.6211 - val_accuracy: 0.6921\n",
      "Epoch 78/100\n",
      "7927/7927 [==============================] - 3s 337us/step - loss: 0.4438 - accuracy: 0.7916 - val_loss: 0.6188 - val_accuracy: 0.7029\n",
      "Epoch 79/100\n",
      "7927/7927 [==============================] - 3s 348us/step - loss: 0.4394 - accuracy: 0.7919 - val_loss: 0.6230 - val_accuracy: 0.7090\n",
      "Epoch 80/100\n",
      "7927/7927 [==============================] - 3s 348us/step - loss: 0.4319 - accuracy: 0.7950 - val_loss: 0.6465 - val_accuracy: 0.6778\n",
      "Epoch 81/100\n",
      "7927/7927 [==============================] - 3s 348us/step - loss: 0.4321 - accuracy: 0.7988 - val_loss: 0.6262 - val_accuracy: 0.6942\n",
      "Epoch 82/100\n",
      "7927/7927 [==============================] - 3s 329us/step - loss: 0.4233 - accuracy: 0.8024 - val_loss: 0.6344 - val_accuracy: 0.6983\n",
      "Epoch 83/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.4282 - accuracy: 0.8006 - val_loss: 0.6255 - val_accuracy: 0.7034\n",
      "Epoch 84/100\n",
      "7927/7927 [==============================] - 3s 326us/step - loss: 0.4229 - accuracy: 0.8047 - val_loss: 0.6448 - val_accuracy: 0.6936\n",
      "Epoch 85/100\n",
      "7927/7927 [==============================] - 3s 358us/step - loss: 0.4149 - accuracy: 0.8114 - val_loss: 0.6492 - val_accuracy: 0.6977\n",
      "Epoch 86/100\n",
      "7927/7927 [==============================] - 3s 345us/step - loss: 0.4136 - accuracy: 0.8074 - val_loss: 0.6634 - val_accuracy: 0.6983\n",
      "Epoch 87/100\n",
      "7927/7927 [==============================] - 3s 346us/step - loss: 0.4197 - accuracy: 0.8022 - val_loss: 0.6699 - val_accuracy: 0.6788\n",
      "Epoch 88/100\n",
      "7927/7927 [==============================] - 3s 335us/step - loss: 0.4091 - accuracy: 0.8133 - val_loss: 0.6485 - val_accuracy: 0.6988\n",
      "Epoch 89/100\n",
      "7927/7927 [==============================] - 3s 347us/step - loss: 0.4101 - accuracy: 0.8143 - val_loss: 0.6791 - val_accuracy: 0.6926\n",
      "Epoch 90/100\n",
      "7927/7927 [==============================] - 3s 349us/step - loss: 0.4144 - accuracy: 0.8035 - val_loss: 0.6762 - val_accuracy: 0.6870\n",
      "Epoch 91/100\n",
      "7927/7927 [==============================] - 3s 339us/step - loss: 0.4088 - accuracy: 0.8153 - val_loss: 0.6801 - val_accuracy: 0.6839\n",
      "Epoch 92/100\n",
      "7927/7927 [==============================] - 3s 331us/step - loss: 0.4026 - accuracy: 0.8152 - val_loss: 0.6711 - val_accuracy: 0.6906\n",
      "Epoch 93/100\n",
      "7927/7927 [==============================] - 3s 348us/step - loss: 0.4018 - accuracy: 0.8188 - val_loss: 0.6774 - val_accuracy: 0.6829\n",
      "Epoch 94/100\n",
      "7927/7927 [==============================] - 3s 330us/step - loss: 0.4010 - accuracy: 0.8166 - val_loss: 0.6984 - val_accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "7927/7927 [==============================] - 3s 375us/step - loss: 0.3971 - accuracy: 0.8176 - val_loss: 0.6810 - val_accuracy: 0.6855\n",
      "Epoch 96/100\n",
      "7927/7927 [==============================] - 3s 332us/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.6908 - val_accuracy: 0.6931\n",
      "Epoch 97/100\n",
      "7927/7927 [==============================] - 3s 347us/step - loss: 0.3919 - accuracy: 0.8211 - val_loss: 0.6793 - val_accuracy: 0.6875\n",
      "Epoch 98/100\n",
      "7927/7927 [==============================] - 3s 340us/step - loss: 0.3937 - accuracy: 0.8267 - val_loss: 0.7063 - val_accuracy: 0.6829\n",
      "Epoch 99/100\n",
      "7927/7927 [==============================] - 3s 324us/step - loss: 0.3981 - accuracy: 0.8209 - val_loss: 0.6913 - val_accuracy: 0.6921\n",
      "Epoch 100/100\n",
      "7927/7927 [==============================] - 2s 311us/step - loss: 0.3810 - accuracy: 0.8277 - val_loss: 0.7051 - val_accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "history8 = SgModel4.fit(train_data, train_label, epochs=Maxepoch, verbose=1, validation_data=(test_data,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories=[history1,history2,history3,history4,history5,history6,history7,history8]\n",
    "Mnames=[ReluModel1.name,ReluModel2.name,ReluModel3.name,ReluModel4.name,\n",
    "       SgModel1.name,SgModel2.name,SgModel3.name,SgModel4.name]\n",
    "\n",
    "nModel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoches=list(range(1,Maxepoch+1))\n",
    "\n",
    "allacc = np.r_[np.r_[tuple([histories[i].history['accuracy'] for i in range(nModel)])],\n",
    "         np.r_[tuple([histories[i].history['val_accuracy'] for i in range(nModel)])]]\n",
    "\n",
    "ymin = np.min(allacc)\n",
    "ymax = np.max(allacc)\n",
    "\n",
    "ymin,ymax = -(ymax-ymin)/10+ymin,(ymax-ymin)/10+ymax\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('accuracy vs epoches')\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "for i in range(nModel):\n",
    "    plt.plot(epoches,histories[i].history['accuracy'],label=Mnames[i])\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title('train')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "for i in range(nModel):\n",
    "    plt.plot(epoches,histories[i].history['val_accuracy'],label=Mnames[i])\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title('test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('accuracy.png')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.7248463094234466, 0.003951314200695363),\n",
       " (0.7246413946151733, 0.004812570778791916),\n",
       " (0.7243852555751801, 0.0030992734866312527),\n",
       " (0.7167008221149445, 0.006061563026425753),\n",
       " (0.7246926248073577, 0.002480268569071051),\n",
       " (0.7243340134620666, 0.0022147439575250093),\n",
       " (0.7247438609600068, 0.002602644072871928),\n",
       " (0.7149590194225312, 0.010973647915812273))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([(np.mean(histories[i].history['val_accuracy'][10:20]),np.std(histories[i].history['val_accuracy'][10:20])) for i in range(nModel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7300204634666443,\n",
       " 0.7320696711540222,\n",
       " 0.7305327653884888,\n",
       " 0.7284836173057556,\n",
       " 0.7320696711540222,\n",
       " 0.7341188788414001,\n",
       " 0.7320696711540222,\n",
       " 0.7284836173057556)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([np.max(histories[i].history['val_accuracy']) for i in range(nModel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TF",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
